<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://0.0.0.0:4800/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4800/" rel="alternate" type="text/html" /><updated>2022-02-28T02:53:44+00:00</updated><id>http://0.0.0.0:4800/feed.xml</id><title type="html">Aiesst</title><subtitle>Aiesst的个人博客</subtitle><author><name>Aiesst</name></author><entry><title type="html">Java Lambda 序列化</title><link href="http://0.0.0.0:4800/2020/11/17/lambda-serialize-1/" rel="alternate" type="text/html" title="Java Lambda 序列化" /><published>2020-11-17T00:00:00+00:00</published><updated>2020-11-17T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2020/11/17/lambda-serialize-1</id><content type="html" xml:base="http://0.0.0.0:4800/2020/11/17/lambda-serialize-1/">Lambda 是 Java8 引进的一项新的能力，日常主要是结合 stream 一起使用，Lambda 也是可以像普通的对象一样进行序列化/反序列化的，就可以像普通对象一样先序列化成字节码然后进行存储或者传输，待需要的时候再将字节码进行反序列化，这样就实现了将一个方法进行了本地存储和传输，通过该方式可以进一步实现类似 Groovy 动态脚本一样的功能

## 序列化
Lambda 的序列化和普通对象的序列化一样，主要使用```ObjectOutputStream/ObjectInputStream``` 
&gt; 该方法就是普通的序列化方法，主要调用了 ```ObjectOutputStream``` 进行序列化输出

```java
/**
 * 序列化普通的 serializable
 *
 * @param serializable lambda 接口
 * @return 序列化数组
 * @throws IOException
*/
@SneakThrows
public static &lt;T extends Serializable&gt; byte[] serialize(@Nonnull T serializable){
    ByteArrayOutputStream outStream = new ByteArrayOutputStream();
    ObjectOutputStream oos = new ObjectOutputStream(outStream);
    oos.writeObject(serializable);
    return outStream.toByteArray();
}
```

## 反序列化
&gt; 反序列化主要调用了 ```ObjectInputStream``` 进行反序列化解析

```java
/**
 * 反序列化普通的 serializable
 *
 * @param inBytes 序列化的数组
 * @return serializable 接口 lambda
 * @throws IOException
 * @throws ClassNotFoundException
 */
@SuppressWarnings(&quot;ALL&quot;)
@SneakThrows
public static &lt;T&gt; T deserialize(@Nonnull byte[] inBytes){
    ByteArrayInputStream inStream = new ByteArrayInputStream(inBytes);
    ObjectInputStream ois = new ObjectInputStream(inStream);
    T obj = (T)ois.readObject();
    return obj;
}
```

## 使用样例
```java
@Test
@SneakThrows
public void serializeLambdaTest(){
    // 这里调用了序列化
    byte[] bytes = LambdaUtil.serialize(
        (Function&lt;String, String&gt; &amp; Serializable)name -&gt; &quot;hello: &quot; + name
    );
    // 这里调用了反序列化
    Function&lt;String, String&gt; func = LambdaUtil.deserialize(bytes);
    Assert.assertEquals(&quot;hello: apple&quot;, func.apply(&quot;apple&quot;));
}
```
&gt; 可见，这里将自定义的 Function 先是序列化成了字节码，然后再将字节码进行了反序列化，同时进行了 ```apply``` 调用
&gt; ```(Function&lt;String, String&gt; &amp; Serializable)``` 这是 Java8 引入的新[语法][href1]


## SerializedLambda
Lambda 的展示形式主要有两种，第一种为 Lambda 表达式，第二种为方法引用，如下
```java
@Test
public void compareTest(){
    List&lt;Integer&gt; numbers = Lists.newArrayList(1,3,2,1,4);
    // Lambda 表达式
    numbers.sort((a,b)-&gt;a.compareTo(b))
    // 方法引用
    numbers.sort(Integer::compareTo)
  
}
```
那么这两种 Lambda 有什么区别呢，如果不涉及到捕获 Lambda 所处的 ```Method/Class``` 等信息没有太大区别，但是当需要通过 ```SerializedLambda``` 去捕获相关信息就会有较大的区别了，`SerializedLambda` 是 Java8 提供的一个新的类，凡是继承了```Serializable```的函数式接口的实例都可以获取一个属于它的```SerializedLambda```实例，提供如下的功能：

1. 引用方法的 Method 信息（方法名，签名）
1. Lambda 的 FunctionInterface 信息（方法名，签名）
1. 引用方法的所在的 Class 
1. Lambda 里面捕获的变量信息

如何得到 ```SerializedLambda``` 呢？主要调用了 ```writeReplace``` 方法实现，如下
```java
/**
 * 获取序列化的 lambda 信息
 * &lt;example&gt;
 * SerializedLambda[
 *   capturingClass=class com.dingtalk.zeus.validator.constraint.SimpleValidAdapterTest,
 *   functionalInterfaceMethod=com/dingtalk/zeus/interfaces/LambdaSerialize.get:(Ljava/lang/Object;)
 *   Ljava/lang/Object;,
 *   implementation=invokeStatic com/dingtalk/zeus/validator/constraint/AtMethods.appCode:(Ljava/lang/String;)
 *   Ljava/lang/Void;,
 *   instantiatedMethodType=(Ljava/lang/String;)Ljava/lang/Void;,
 *   numCaptured=0
 * ]
 * &lt;/example&gt;
 *
 * @return 序列化的 lambda 对象
 * @throws Exception invoke 异常
*/
public static SerializedLambda getSerializedLambda(
    @NonNull Class&lt;? extends Serializable&gt; funInterfaceCls,
    @NonNull Serializable serializable
) throws Exception {
    Method write = funInterfaceCls.getDeclaredMethod(&quot;writeReplace&quot;);
    write.setAccessible(true);
    return (SerializedLambda)write.invoke(serializable);
}
```
这里获取的 ```SerializedLambda``` 对象的所有属性都是 ```String``` 类型的，需要再通过反射获取的真实的 ```Method``` 和 ```Class``` 信息。
获取了 ```SerializedLambda``` 并得到了 ```Method``` 和 ```Class``` 之后有什么用途呢？其主要用途如下：
1. 获取 ```getter/setter``` 对应的属性名字
&gt; 比如，在 ```tk.mybatis``` 里面可以直接通过 ```obj::getColumn``` 直接就能映射到数据库的 ```column``` 字段
1. 快速获取 ```Method``` 信息
```java
    // 传统获取 method
    MethodUtils.getMatchingMethod(BaseMockTest.class,&quot;init&quot;,String.class)
    // 基于 SerializedLambda 获取，LambdaUtil 是自己封装的，解析 SerializedLambda 的 Method 信息
    LambdaUtil.getMethod(BaseMockTest::init)
    // 传统方式依赖方法名和签名，如果方法重构了会有影响，
    // 第二种方式使用起来更简单，同时方法重构会自动跟着重构
```

## 总结
Java Lambda 的序列化/反序列化和普通对象的使用方法一致，Java8 引入了 ```SerializedLambda``` 对象，该对象主要是应用在方法引用的 Lambda 上面，通过它可以快速获取引用方法的信息，主要包括引用方法的 ```Method```，```Class```，```CaptureVars``` 等信息，通过序列化/反序列化可以很方便地将一个 Java Lambda 进行传输，可以使用类似动态脚本的能力。

[href1]: https://docs.oracle.com/javase/specs/jls/se8/html/jls-15.html#jls-15.16</content><author><name>Aiesst</name></author><category term="后端" /><category term="Java" /><category term="序列化" /><category term="Lambda" /><summary type="html">序列化是一种常见的数据传输机制，但是 Lambda 序列化可以将 Java 的一个方法进行传输，从而实现动态脚本等功能</summary></entry><entry><title type="html">机器学习-Adaboost算法</title><link href="http://0.0.0.0:4800/2019/04/13/ml-adaboost/" rel="alternate" type="text/html" title="机器学习-Adaboost算法" /><published>2019-04-13T00:00:00+00:00</published><updated>2019-04-13T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/13/ml-adaboost</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/13/ml-adaboost/">　　Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。

　　Adaboost 的算法思想是</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="Adaboost" /><summary type="html">Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。</summary></entry><entry><title type="html">SMO 算法的代码实现</title><link href="http://0.0.0.0:4800/2019/04/12/ml-smo-py/" rel="alternate" type="text/html" title="SMO 算法的代码实现" /><published>2019-04-12T00:00:00+00:00</published><updated>2019-04-12T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/12/ml-smo-py</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/12/ml-smo-py/">　　SMO 是解决 SVM 中目标函数优化的一个快速的算法，本文通过 Python 代码实现了该算法，通过将原算法公式和代码进行一一比对让读者更能理会整个算法原理和实现步骤。

　　如果对文中的相关公式不了解请参考另一篇理论文章 [SMO 算法超详细解析][href2]

## 准备

本算法实现参考于《机器学习实战》，相关的数据资源请自行下载
&gt; [https://pan.baidu.com/s/1Gc7BDmNyBfGQlfVvhzyZFw][href1] 提取码：ywuh 

本文是基于 ```Python``` 来实现的整个算法，且依赖于 ```numpy```

本文的测试数据集在 ch06 文件下面的几个 txt 文件，这些测试文件的数据都是标准的二分类数据

   [![svm-test-set][img1]][img1]{:data-lightbox=&quot;smo&quot;}

## SMO 功能函数
### 加载数据
　　将上图中的 txt 测试数据加载到内存中，并生成指定的矩阵格式，其中特征数据赋值给了 X 矩阵，分类数据赋值给了 Y 矩阵
```python
def loadDataSet(fileName):
    &quot;&quot;&quot;
    加载文本数据
    :param fileName:
    :return:
    &quot;&quot;&quot;
    X = []
    Y = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = line.strip().split(&apos;\t&apos;)
        X.append([float(lineArr[0]), float(lineArr[1])])
        Y.append(float(lineArr[2]))
    # 分别转成矩阵，其中分类矩阵转置成一列
    return mat(X), mat(Y).T
```

### 注入数据
将一些基础数据通过构造函数注入进行注入
```python
class SMO:
    def __init__(self, X, Y, C, e, gaussDelta=1.3):
        &quot;&quot;&quot;
        初始化构造函数，注入训练样本，常量，容错率
        :param X: 样本特征
        :param Y: 样本分类，只能取 {1,-1}
        :param C: 常量
        :param e: 容错率
        :param gaussDetla: 高斯核函数的分母 delta 值
        &quot;&quot;&quot;
        self.X = X
        self.Y = Y
        self.C = C
        self.tol = e
        self.N = shape(X)[0]
        self.alphas = mat(zeros((self.N, 1)))
        self.b = 0
        self.eCache = mat(zeros((self.N, 2)))
        self.K = mat(zeros((self.N, self.N)))
        for i in range(self.N):
            self.K[:, i] = self.kernelGauss(self.X, self.X[i, :], gaussDelta)
```
### 高斯核

上述代码的最后有一行进行了高斯核处理，并将处理结果 $$K{ij}$$ 进行了缓存：

$$
K(x, y)=\exp \left(-\frac{\|x-y\|^{2}}{2 \sigma^{2}}\right)\tag{2-1}
$$

通过如下代码便可以实现高斯核，同时通过 ```calcKernel``` 方法直接返回了缓存的 $$K_{i,j}$$ 结果
```python
   def kernelGauss(self, X, Y, delta):
        &quot;&quot;&quot;
        计算高斯核函数值
        :param delta:
        :return:
        &quot;&quot;&quot;
        m, n = shape(X)
        k = mat(zeros((m, 1)))
        for j in range(m):
            diff = X[j, :] - Y
            k[j] = diff * diff.T
        return exp(-k / (2 * math.pow(delta, 2)))
    
     def calcKernel(self, i, j):
        &quot;&quot;&quot;
        这里直接返回的之前缓存的核函数值
        :param i:
        :param j:
        :return:
        &quot;&quot;&quot;
        return self.K[i, j]
```

### 计算 $$E_i$$
$$E_i$$ 表示了预测值与真实值的差，其计算方法如下：

$$
    E_i = f(x_i) - y_i =\sum_{j=1}^{N} \alpha_{j} y_{j} K_{ij}+b - y_i\tag{2-2}
$$


```python
  def calcEi(self, i):
        &quot;&quot;&quot;
        计算 f(x_i) - y_i
        :param i: 索引
        :return: 预测值和真实值的差值
        &quot;&quot;&quot;
        aiyi = multiply(self.alphas, self.Y)
        ki = self.K[:, i]
        fxi = float(aiyi.T * ki) + self.b
        ei = fxi - float(self.Y[i])
        return ei
```

### 选择第二个变量 $$\alpha_j$$
由于第二个变量的选择比较麻烦，所以将其单独提取出来

```python
    def selectJ(self, i, ei):
        &quot;&quot;&quot;
        选择 |Ei - Ej| 取最大值的时候的 j,Ej，要求 Ej 是之前迭代的，否者返回随机选取的 j,Ej
        :param i: 第一个变量
        :param ei: 第一个变量的 Ei
        :return: 第二个变量的 j,Ej
        &quot;&quot;&quot;
        j = -1
        maxDeltaE = 0
        ej = 0
        self.eCache[i] = [1, ei]
        # 要求选择的 Ej 必须是之前迭代过的，否则返回随机值
        validEcacheList = nonzero(self.eCache[:, 0].A)[0]
        if len(validEcacheList) &gt; 0:
            for k in validEcacheList:
                if k == i:
                    continue
                ek = self.calcEi(k)
                deltaE = abs(ei - ek)
                if deltaE &gt; maxDeltaE:
                    maxDeltaE = deltaE
                    ej = ek
                    j = k
            return j, ej
        else:
            j = self.selectJRand(i, self.N)
            ej = self.calcEi(j)
            return j, ej

    def selectJRand(self, i, n):
        &quot;&quot;&quot;
        随机选择第二个变量
        :param i:
        :param n:
        :return:
        &quot;&quot;&quot;
        j = i
        while j == i:
            j = int(random.uniform(0, n))
        return j

    def updateEi(self, i):
        &quot;&quot;&quot;
        更新 Ei 的缓存
        :param i:
        :return:
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        self.eCache[i] = [1, ei]
```

## SMO 核心处理
### $$\alpha$$ 更新
#### $$\alpha_2$$ 的更新

$$
    \alpha_2^{new,unc}=\alpha_2^{old}+\frac{y_2(E_1-E_2)}{\eta}
    \tag{2-3}
$$

其中，$$\alpha_2^{new}$$ 表示本次迭代的计算值，$$\alpha_2^{old}$$ 为上一次的迭代值 &lt;br/&gt;
　　$$E_i = f(x_i) - y_i$$ 表示预测值与真实值的差 &lt;br/&gt;
　　$$\eta=K_{11}+K_{22}-2K_{12} $$
$$

$$
    \alpha_2^{new} = 
\begin{cases}
    H, \alpha_2^{new,unc} &gt; H\\
    \alpha_2^{new,unc}, L \le \alpha_2^{new,unc} \le H \\
    L, \alpha_2^{new,unc} &lt; L
\end{cases} \tag{2-4}
$$

代码实现，用 ```alphas[j]``` 表示 $$\alpha_2$$
```python
    eta = self.calcKernel(i, i) + self.calcKernel(j, j) - 2 * self.calcKernel(i, j)
    ajOld = self.alphas[j].copy()
    if self.Y[i] != self.Y[j]:
        L = max(0, ajOld - aiOld)
        H = min(self.C, self.C + ajOld - aiOld)
    else:
        L = max(0, aiOld + ajOld - self.C)
        H = min(self.C, aiOld + ajOld)
    self.alphas[j] = ajOld + self.Y[j] * (ei - ej) / eta
    self.alphas[j] = self.truncateAlpha(self.alphas[j], H, L)
```
其中 ```self.truncateAlpha(self.alphas[j],H,L)``` 为 $$\alpha_j$$ 的约束

```python
    def truncateAlpha(self, aj, H, L):
        &quot;&quot;&quot;
        对 Aj 进行截取，只能在 H L 之内
        :param aj:
        :param H:
        :param L:
        :return:
        &quot;&quot;&quot;
        if aj &gt; H:
            return H
        elif aj &lt; L:
            return L
        else:
            return aj
```
#### $$\alpha_1$$ 的更新
$$
    \alpha_{1}^{n e w}=\alpha_{1}^{o l d}+y_{1} y_{2}\left(\alpha_{2}^{o l d}-\alpha_{2}^{n e w}\right)\tag{2-5}
$$

代码实现，用 ```alphas[i]``` 表示 $$\alpha_1$$

```python
        aiOld = self.alphas[i].copy()
        self.alphas[i] = aiOld + self.Y[i] * self.Y[j] * (ajOld - self.alphas[j])
```

### $$b$$ 的更新
1.　若 $$0 &lt; \alpha_1^{new} &lt; C$$，则

$$
   b^{new} =  b_{1}^{new}=-E_{1}-y_{1} K_{11}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{21}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}\tag{2-6}
$$


2.　若 $$0 &lt; \alpha_2^{new} &lt; C$$，则

$$
   b^{new} =  b_{2}^{new}=-E_{2}-y_{1} K_{12}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{22}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}\tag{2-7}
$$

3.　若同时满足 $$0 &lt; \alpha_i^{new} &lt; C$$，则

$$
    b^{new} = b_1^{new} = b_2^{new}\tag{2-8}
$$

4.　若同时不满足 $$ 0 &lt; \alpha_i^{new} &lt; C $$，则

$$
    b^{new} = \frac{b_1^{new}  + b_2^{new}}{2} \tag{2-9}
$$

代码实现
```python
        b1 = -ei - self.Y[i] * self.calcKernel(i, i) * (self.alphas[i] - aiOld) \
            - self.Y[j] * self.calcKernel(j, i) * (self.alphas[j] - ajOld) + self.b

        b2 = -ej - self.Y[j] * self.calcKernel(i, j) * (self.alphas[i] - aiOld) \
            - self.Y[j] * self.calcKernel(j, j) * (self.alphas[j] - ajOld) + self.b

        if 0 &lt; self.alphas[j] &lt; self.C:
            self.b = b1
        elif 0 &lt; self.alphas[i] &lt; self.C:
            self.b = b2
        else:
            self.b = (b1 + b2) / 2.0
```

### $$\alpha$$ 和 $$b$$ 更新代码

```python
    def updateAlphaB(self, i, e=0.00001):
        &quot;&quot;&quot;
        利用 SMO 算法优化一次 alpha_i, alpha_j, b
        :param i: 训练样本索引
        :param e: 最小更新步长
        :return: 更新成功返回 1，失败返回 0
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        # 选择那些在容错率之外的样本作为第一个变量
        if ((self.Y[i] * ei &lt; -self.tol) and (self.alphas[i] &lt; self.C)) or \
                ((self.Y[i] * ei &gt; self.tol) and (self.alphas[i] &gt; 0)):
            j, ej = self.selectJ(i, ei)
            aiOld = self.alphas[i].copy()
            ajOld = self.alphas[j].copy()
            if self.Y[i] != self.Y[j]:
                L = max(0, ajOld - aiOld)
                H = min(self.C, self.C + ajOld - aiOld)
            else:
                L = max(0, aiOld + ajOld - self.C)
                H = min(self.C, aiOld + ajOld)
            if L == H:
                print(&quot;L == H&quot;)
                return 0
            eta = self.calcKernel(i, i) + self.calcKernel(j, j) - 2 * self.calcKernel(i, j)
            # eta 类似于二阶导数值，只有当它 大于 0 才能取最小值
            if eta &lt;= 0:
                print(&quot;eta &lt;= 0&quot;)
                return 0
            # 计算 alpha_j 并截取在[H,L]之内
            self.alphas[j] = ajOld + self.Y[j] * (ei - ej) / eta
            self.alphas[j] = self.truncateAlpha(self.alphas[j], H, L)
            self.updateEi(j)
            if abs(self.alphas[j] - ajOld) &lt; e:
                print(&quot;j not moving enough&quot;)
                return 0
            self.alphas[i] = aiOld + self.Y[i] * self.Y[j] * (ajOld - self.alphas[j])
            self.updateEi(i)

            # 更新 b 的值
            b1 = -ei - self.Y[i] * self.calcKernel(i, i) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, i) * (self.alphas[j] - ajOld) + self.b

            b2 = -ej - self.Y[j] * self.calcKernel(i, j) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, j) * (self.alphas[j] - ajOld) + self.b

            if 0 &lt; self.alphas[j] &lt; self.C:
                self.b = b1
            elif 0 &lt; self.alphas[i] &lt; self.C:
                self.b = b2
            else:
                self.b = (b1 + b2) / 2.0
            return 1
        else:
            return 0

```

### 训练样本
训练样本主要是从样本的非边界值和所有值来回进行选取

```python
    def train(self, maxIter):
        &quot;&quot;&quot;
        训练样本
        :param maxIter: 最大迭代次数
        :return: 训练好的 b,alphas
        &quot;&quot;&quot;
        iter = 0
        entireSet = True
        alphaPairsChanged = 0
        # 在所有值和非边界值上面来回切换选取变量
        while (iter &lt; maxIter) and ((alphaPairsChanged &gt; 0) or entireSet):
            alphaPairsChanged = 0
            # 遍历所有值，更新那些没有迭代过的数据
            if entireSet:
                for i in range(self.N):
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;fullSet, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                    iter += 1
            # 遍历非边界值
            else:
                # 在 alphas 中取出大于 0 小于 c 的索引值
                # 即更新那些之前迭代过的 alpha_i alpha_j
                nonBoundIs = nonzero((self.alphas.A &gt; 0) * (self.alphas.A &lt; self.C))[0]
                for i in nonBoundIs:
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;non-bound, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                iter += 1
            if entireSet:
                entireSet = False
            elif alphaPairsChanged == 0:
                entireSet = True
            print(&quot;iteration number: %d&quot; % iter)
        return self.b, self.alphas
```

## 样本测试
这里使用了两组样本，其中 ```testSetRBF.txt``` 为训练样本，```testSetRBF2.txt``` 为测试样本
```python
if __name__ == &apos;__main__&apos;:
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF.txt&quot;)
    smo = SMO(X, Y, 200, 0.0001)
    b, alphas = smo.train(10000)
    # 支持向量即 alphas 大于 0 对应的那些有效的样本向量，这些向量是落在 SVM 的边界上面的
    # 支持向量的索引
    svIndices = nonzero(smo.alphas.A &gt; 0)[0]
    # 支持向量特征
    xSv = X[svIndices]
    # 支持向量分类
    ySv = Y[svIndices]
    print(&quot;there are %d Support Vectors&quot; % shape(xSv)[0])
    m, n = shape(X)
    errorCount = 0
    delta = 1.3
    for i in range(m):
        # 映射到核函数值
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1
    # 训练样本误差
    print(&quot;the training error rate is : %f&quot; % (float(errorCount / m)))

    errorCount = 0
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF2.txt&quot;)
    m, n = shape(X)
    for i in range(m):
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1

    # 测试样本误差
    print(&quot;the test error rate is : %f&quot; % (float(errorCount / m)))
```
最终运行的效果截图

   [![svm-test][img2]][img2]{:data-lightbox=&quot;smo&quot;}
## 总结
　　SMO 算法的实现过程并不复杂，主要处理了核函数，变量$$\alpha_1,\alpha_2$$的选取，$$\alpha,b$$ 的更新，样本训练的终止条件等问题&lt;br/&gt;
　　核函数主要使用了高斯核，当然也可以替换成其它的核函数。&lt;br/&gt;
　　$$\alpha_1$$ 变量的选取是通过容错率 ```self.tol``` 来进行抉择的，主要选择那些在容错率范围之外的数据来作为 $$\alpha_1$$。&lt;br/&gt;
　　$$\alpha_2$$ 变量的选取是当 $$|E_1 - E_2|$$ 取最大值的时候对应的变量。&lt;br/&gt;
　　样本训练的终止条件通过最大迭代次数、更新是否成功、完整集训练等标志来确定的。

## 附录
### 完整代码
文件 ```smo.py```

```python
from numpy import *
class SMO:
    def __init__(self, X, Y, C, e, gaussDelta=1.3):
        &quot;&quot;&quot;
        初始化构造函数，注入训练样本，常量，容错率
        :param X: 样本特征
        :param Y: 样本分类，只能取 {1,-1}
        :param C: 常量
        :param e: 容错率
        &quot;&quot;&quot;
        self.X = X
        self.Y = Y
        self.C = C
        self.tol = e
        self.N = shape(X)[0]
        self.alphas = mat(zeros((self.N, 1)))
        self.b = 0
        self.eCache = mat(zeros((self.N, 2)))
        self.K = mat(zeros((self.N, self.N)))
        for i in range(self.N):
            self.K[:, i] = self.kernelGauss(self.X, self.X[i, :], gaussDelta)

    def calcEi(self, i):
        &quot;&quot;&quot;
        计算 f(x_i) - y_i
        :param i: 索引
        :return: 预测值和真实值的差值
        &quot;&quot;&quot;
        aiyi = multiply(self.alphas, self.Y)
        ki = self.K[:, i]
        fxi = float(aiyi.T * ki) + self.b
        ei = fxi - float(self.Y[i])
        return ei

    def selectJ(self, i, ei):
        &quot;&quot;&quot;
        选择 |Ei - Ej| 取最大值的时候的 j,Ej，要求 Ej 是之前迭代的，否者返回随机选取的 j,Ej
        :param i: 第一个变量
        :param ei: 第一个变量的 Ei
        :return: 第二个变量的 j,Ej
        &quot;&quot;&quot;
        j = -1
        maxDeltaE = 0
        ej = 0
        self.eCache[i] = [1, ei]
        validEcacheList = nonzero(self.eCache[:, 0].A)[0]
        if len(validEcacheList) &gt; 0:
            for k in validEcacheList:
                if k == i:
                    continue
                ek = self.calcEi(k)
                deltaE = abs(ei - ek)
                if deltaE &gt; maxDeltaE:
                    maxDeltaE = deltaE
                    ej = ek
                    j = k
            return j, ej
        else:
            j = self.selectJRand(i, self.N)
            ej = self.calcEi(j)
            return j, ej

    def selectJRand(self, i, n):
        &quot;&quot;&quot;
        随机选择第二个变量
        :param i:
        :param n:
        :return:
        &quot;&quot;&quot;
        j = i
        while j == i:
            j = int(random.uniform(0, n))
        return j

    def updateEi(self, i):
        &quot;&quot;&quot;
        更新 Ei 的缓存
        :param i:
        :return:
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        self.eCache[i] = [1, ei]

    def updateAlphaB(self, i, e=0.00001):
        &quot;&quot;&quot;
        利用 SMO 算法优化一次 alpha_i 和 alpha_j
        :param i:
        :param e:
        :return:
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        # 选择那些在容错率之外的样本作为第一个变量
        if ((self.Y[i] * ei &lt; -self.tol) and (self.alphas[i] &lt; self.C)) or \
                ((self.Y[i] * ei &gt; self.tol) and (self.alphas[i] &gt; 0)):
            j, ej = self.selectJ(i, ei)
            aiOld = self.alphas[i].copy()
            ajOld = self.alphas[j].copy()
            if self.Y[i] != self.Y[j]:
                L = max(0, ajOld - aiOld)
                H = min(self.C, self.C + ajOld - aiOld)
            else:
                L = max(0, aiOld + ajOld - self.C)
                H = min(self.C, aiOld + ajOld)
            if L == H:
                print(&quot;L == H&quot;)
                return 0
            eta = self.calcKernel(i, i) + self.calcKernel(j, j) - 2 * self.calcKernel(i, j)
            # eta 类似于二阶导数值，只有当它 大于 0 才能取最小值
            if eta &lt;= 0:
                print(&quot;eta &lt;= 0&quot;)
                return 0
            # 计算 alpha_j 并截取在[H,L]之内
            self.alphas[j] = ajOld + self.Y[j] * (ei - ej) / eta
            self.alphas[j] = self.truncateAlpha(self.alphas[j], H, L)
            self.updateEi(j)
            if abs(self.alphas[j] - ajOld) &lt; e:
                print(&quot;j not moving enough&quot;)
                return 0
            self.alphas[i] = aiOld + self.Y[i] * self.Y[j] * (ajOld - self.alphas[j])
            self.updateEi(i)

            # 更新 b 的值
            b1 = -ei - self.Y[i] * self.calcKernel(i, i) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, i) * (self.alphas[j] - ajOld) + self.b

            b2 = -ej - self.Y[j] * self.calcKernel(i, j) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, j) * (self.alphas[j] - ajOld) + self.b

            if 0 &lt; self.alphas[j] &lt; self.C:
                self.b = b1
            elif 0 &lt; self.alphas[i] &lt; self.C:
                self.b = b2
            else:
                self.b = (b1 + b2) / 2.0
            return 1
        else:
            return 0

    def truncateAlpha(self, aj, H, L):
        &quot;&quot;&quot;
        对 Aj 进行截取，只能在 H L 之内
        :param aj:
        :param H:
        :param L:
        :return:
        &quot;&quot;&quot;
        if aj &gt; H:
            return H
        elif aj &lt; L:
            return L
        else:
            return aj

    def calcKernel(self, i, j):
        &quot;&quot;&quot;
        这里直接返回的之前缓存的核函数值
        :param i:
        :param j:
        :return:
        &quot;&quot;&quot;
        return self.K[i, j]

    def kernelGauss(self, X, Y, delta):
        &quot;&quot;&quot;
        计算高斯核函数值
        :param delta:
        :return:
        &quot;&quot;&quot;
        m, n = shape(X)
        k = mat(zeros((m, 1)))
        for j in range(m):
            diff = X[j, :] - Y
            k[j] = diff * diff.T
        return exp(-k / (2 * math.pow(delta, 2)))

    def train(self, maxIter):
        &quot;&quot;&quot;
        训练样本
        :param maxIter: 最大迭代次数
        :return: 训练好的 b,alphas
        &quot;&quot;&quot;
        iter = 0
        entireSet = True
        alphaPairsChanged = 0
        # 在所有值和非边界值上面来回切换选取变量
        while (iter &lt; maxIter) and ((alphaPairsChanged &gt; 0) or entireSet):
            alphaPairsChanged = 0
            # 遍历所有值
            if entireSet:
                for i in range(self.N):
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;fullSet, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                    iter += 1
            # 遍历非边界值
            else:
                # 在 alphas 中取出大于 0 小于 c 的索引值
                nonBoundIs = nonzero((self.alphas.A &gt; 0) * (self.alphas.A &lt; self.C))[0]
                for i in nonBoundIs:
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;non-bound, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                iter += 1
            if entireSet:
                entireSet = False
            elif alphaPairsChanged == 0:
                entireSet = True
            print(&quot;iteration number: %d&quot; % iter)
        return self.b, self.alphas
```

文件 ```test.py```
```python
from smo import *
from numpy import *

def loadDataSet(fileName):
    &quot;&quot;&quot;
    加载文本数据
    :param fileName:
    :return:
    &quot;&quot;&quot;
    X = []
    Y = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = line.strip().split(&apos;\t&apos;)
        X.append([float(lineArr[0]), float(lineArr[1])])
        Y.append(float(lineArr[2]))
    # 分别转成矩阵，其中分类矩阵转置成一列
    return mat(X), mat(Y).T


if __name__ == &apos;__main__&apos;:
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF.txt&quot;)
    smo = SMO(X, Y, 200, 0.0001)
    b, alphas = smo.train(10000)
    # 支持向量的索引
    svIndices = nonzero(smo.alphas.A &gt; 0)[0]
    # 支持向量特征
    xSv = X[svIndices]
    # 支持向量分类
    ySv = Y[svIndices]
    print(&quot;there are %d Support Vectors&quot; % shape(xSv)[0])
    m, n = shape(X)
    errorCount = 0
    delta = 1.3
    for i in range(m):
        # 映射到核函数值
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1
    # 训练样本误差
    print(&quot;the training error rate is : %f&quot; % (float(errorCount / m)))

    errorCount = 0
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF2.txt&quot;)
    m, n = shape(X)
    for i in range(m):
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1

    # 测试样本误差
    print(&quot;the test error rate is : %f&quot; % (float(errorCount / m)))
```
[href1]: https://pan.baidu.com/s/1Gc7BDmNyBfGQlfVvhzyZFw
[href2]: /2019/04/10/ml-svm-smo/

[img1]: /images/post/ml/svm-test-set.jpg
[img2]: /images/post/ml/svm-test.jpg</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="SVM" /><category term="SMO" /><category term="Python" /><summary type="html">SMO 是解决 SVM 中目标函数优化的一个快速的算法，本文通过 Python 代码实现了该算法，通过将原算法公式和代码进行一一比对让读者更能理会整个算法原理和实现步骤。</summary></entry><entry><title type="html">SMO 算法超详细解析</title><link href="http://0.0.0.0:4800/2019/04/10/ml-svm-smo/" rel="alternate" type="text/html" title="SMO 算法超详细解析" /><published>2019-04-10T00:00:00+00:00</published><updated>2019-04-10T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/10/ml-svm-smo</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/10/ml-svm-smo/">　　1996年，John Platt 发布一个称为 SMO（Sequential Minimal Optimization，序列最小优化）的强大算法，用于训练 SVM，该算法的核心思想是将原问题分解成多个小问题分别进行优化求解，即 SMO 算法是为了解决 SVM 中的优化目标函数。

　　本文对于 SMO 算法进行了非常详细的剖析，建议读者对里面的公式推导进行亲自的演算，本文需要 SVM 的相关基础，如果对于 SVM 不熟悉可以参考 [支持向量机通俗导论（理解SVM的三层境界）][href1]。

### 优化目标

SVM 的优化目标函数：

$$
\begin{split}
    \mathop{min}\limits_{\vec{\alpha}} \Psi(\vec{\alpha}) = \begin{cases}
        \underbrace{ min }_{\alpha}  \frac{1}{2} \sum\limits_{i=1}^{N} \sum\limits_{j=1}^{N} \alpha_i\alpha_jy_iy_jK(x_i,x_j) - \sum\limits_{i=1}^{N}\alpha_i\\
        s.t. \; \sum\limits_{i=1}^{N}\alpha_iy_i = 0 \\
        0 \le \alpha_i \le C
    \end{cases}
\end{split}\tag{1-1}
$$

其中，$$x_i$$ 表示样本特征&lt;br/&gt;
　　$$y_i$$ 表示样本标签，且 $$y_i \in \{-1,1\}$$ &lt;br/&gt;
　　$$\alpha_i$$ 为要求解的参数 &lt;br/&gt;
　　$$C$$ 为惩罚系数（自己设定）

### SMO 算法剖析
　　SMO 算法的基本思想是将原问题求解 $$(\alpha_1,\alpha_2,...,\alpha_N)$$ 这 $$N$$ 个参数的问题分解成多个子二次规划的问题分别求解，每个子问题只需要求解其中的 2 个参数，每次通过启发式选择两个变量进行优化，不断循环，直到达到函数的最优值。

#### 选择 $$\alpha_1$$ $$\alpha_2$$ 为变量
　　将 $$\Psi(\vec{\alpha})$$ 中 $$\alpha_1,\alpha_2$$ 视作变量，其余的 $$\alpha_i i=3,4,...,N$$ 的参数视为常数，则原优化目标函数变换如下：

$$
\begin{split}
\begin{align*}
    min\Psi(\alpha_1,\alpha_2)  =&amp;\frac{1}{2}K_{11}\alpha_{1}^2y_1^2 + \frac{1}{2}K_{22}\alpha_{2}^2y_2^2 \\
   &amp; + \frac12K_{12}\alpha_1\alpha_2y_1y_2 + \frac12K_{21}\alpha_2\alpha_1y_2y_1 \\
   &amp; - (\alpha_1 + \alpha_2)  + y_1v_1\alpha_1 + y_2v_2\alpha_2 + P
\end{align*}
\end{split}\tag{2-1}
$$

由于，$$y_i^2 = 1$$，$$K_{ij}= K_{ji}$$，化简可得：

$$
\begin{split}
\begin{align*}
    min\Psi(\alpha_1,\alpha_2) 
       =&amp;\frac12K_{11}\alpha_1^2 + \frac12K_{22}\alpha_2^2 + K_{12}\alpha_1\alpha_2y_1y_2\\ 
       &amp;-(\alpha_1 + \alpha_2) + y_1v_1\alpha_1 + y_2v_2\alpha_2 + P
\end{align*}
\end{split}\tag{2-2}
$$

其中，$$K_{ij}$$ 为核函数&lt;br/&gt;
　　$$v_i = \sum\limits_{j=3}^{N} \alpha_jy_jK_{ij} = 0 $$ &lt;br/&gt;
　　$$P$$ 为常数项

#### 用 $$\alpha_2$$ 表示 $$\alpha_1$$

由 $$\sum\limits_{i=1}^{N} \alpha_iy_i = 0$$ 得：

$$
    \alpha_1y_1 + \alpha_2y_2 = - \sum\limits_{i=3}^{N} \alpha_iy_i = \zeta \tag{2-3}
$$

等式两边同时乘 $$y_1$$ 可得：

$$
    \alpha_1 = (\zeta - y_2\alpha_2)y_1 \tag{2-4}
$$

将 (2-4) 代入到 (2-2) 可得：

$$
\begin{align*}
    \Psi(\alpha_2) = &amp;\frac12K_{11}(\zeta - \alpha_2y_2)^2y_1^2 + \frac12K_{22}\alpha_2^2 + K_{12}(\zeta - \alpha_2y_2)\alpha_2y_1^2y_2\\
                    &amp; -(\zeta - \alpha_2y_2)y_1 - \alpha_2 + v_1(\zeta - \alpha_2y_2)y_1^2 + y_2v_2\alpha_2 + P

\end{align*} \tag{2-5}
$$

化简可得：

$$
    \begin{align*}
        \Psi(\alpha_2) = &amp; \frac12K_{11}(\zeta - \alpha_2y_2)^2 + \frac12K_{22}\alpha_2^2 + K_{12}(\zeta - \alpha_2y_2)\alpha_2y_2\\
        &amp; -(\zeta - \alpha_2y_2)y_1 - \alpha_2 + v_1(\zeta - \alpha_2y_2) + y_2v_2\alpha_2 + P
    \end{align*} \tag{2-6}
$$

#### 对 $$\alpha_2$$ 求极值
由 (2-6) 可知，现在目标函数只是关于 $$\alpha_2$$ 的函数，对其求导并令它等于 0 

$$
\begin{align}
    \frac{\partial \Psi (\alpha_2)}{\partial \alpha_2}&amp;=(K_{11}+K_{22}-2K_{12})\alpha_2-K_{11}\zeta y_2+K_{12}\zeta y_2\\
    &amp;\quad+y_1y_2-1-v_1y_2+v_2y_2\\
    &amp; =0
\end{align} \tag{2-7}
$$

SMO 的思想是一个迭代求解的思想，所以必须构造出 $$\alpha_2^{new}$$ 与 $$\alpha_2^{old}$$ 之间的关系，由 (2-3) 可知：

$$
    \alpha_1^{new}y_1 + \alpha_2^{new}y_2 = \alpha_1^{old}y_1 + \alpha_2^{old}y_2 = \zeta \tag{2-8}
$$

由

 $$
 \begin{align*}
    &amp;f(x) =\omega^T x + b  = \sum_{i=1}^{N} \alpha_iy_iK_{ix} + b\\
    &amp;v_i = \sum\limits_{j=3}^{N}\alpha_jy_jK_{ij} \quad\quad i=1,2
 \end{align*} \tag{2-9}
 $$

 可得

 $$
 \begin{align*}
    v_1 = f(x_1) - \sum\limits_{j=1}^{2}\alpha_jy_jK_{1j} - b = f(x) - \alpha_1y_1K_{11} - \alpha_2y_2K_{12} - b \\
    v_2 = f(x_2) - \sum\limits_{j=1}^{2}\alpha_jy_jK_{2j} - b = f(x) - \alpha_1y_1K_{21} - \alpha_2y_2K_{22} - b 
\end{align*} \tag{2-10}
 $$

 将等式 (2-7) 中的 $$\zeta$$ 替换成 (2-8)，$$v_i$$ 替换成 (2-9)，$$\alpha_2$$ 表示待求值，为了和 (2-8) 中的 $$\alpha_2^{old}$$ 区分则用 $$\alpha_2^{new}$$ 表示：

$$
 \begin{align*}
    \frac{\partial \Psi (\alpha_2)}{\partial \alpha_2} = &amp;(K_{11} + K_{22} -2K_{12})\alpha_2^{new} - K_{11}(\alpha_1^{old}y_1 + \alpha_2^{old}y_2)y_2\\
    &amp;+ K_{12}(\alpha_1^{old}y_1 + \alpha_2^{old}y_2)y_2 + y_1y_2 - 1\\
    &amp;- \left[f(x_1) - \alpha_1^{old}y_1K_{11} - \alpha_2^{old}y_2K_{12} - b\right]y_2 \\
    &amp;+ \left[f(x_2) - \alpha_1^{old}y_1K_{21} - \alpha_2^{old}y_2K_{22} - b\right]y_2 \\
    &amp;= 0
 \end{align*} \tag{2-11}
 $$


对 (2-11) 进行展开

$$
\begin{align*}
    (k_{11} + K_{22} - 2K_{12})\alpha_2^{new} = &amp; K_{11}\alpha_1^{old}y_1y_2 + K_{11}\alpha_2^{old}y_2^2 - K_{12}\alpha_1^{old}y_1y_2\\
     &amp; - K_{12}\alpha_2^{old}y_2^2 - y_1y_2 + 1 + f(x_1)y_2 - K_{11}\alpha_1^{old}y_1y_2 \\
     &amp; - K_{12}\alpha_2^{old}y_2^2 - by_2 - f(x_2)y_2 + K_{12}\alpha_1^{old}y_1y_2 \\
     &amp; + K_{22}\alpha_2^{old}y_2^2 + by_2
\end{align*} \tag{2-12}
$$

由 $$y_i^2 = 1$$ 化简可得

 $$
 \begin{align*}
    (K_{11}+K_{22}-2K_{12})\alpha_2^{new}=&amp;(K_{11}+K_{22}-2K_{12})\alpha_2^{old}\\
    &amp; +y_2\left[(f(x_1) - y_1) - (f(x_2) - y_2)\right]
\end{align*}\tag{2-13}
 $$

令 $$Ei = f(x_i) - y_i$$，$$\eta = K_{11} + K_{22} - 2K_{12}$$，可得

 $$
    \alpha_2^{new}=\alpha_2^{old}+\frac{y_2(E_1-E_2)}{\eta}
    \tag{2-14}
 $$

其中，$$\alpha_2^{new}$$ 表示本次迭代的计算值，$$\alpha_2^{old}$$ 为上一次的迭代值 &lt;br/&gt;
　　$$E_i = f(x_i) - y_i$$ 表示预测值与真实值的差 &lt;br/&gt;
　　$$\eta=K_{11}+K_{22}-2K_{12} $$ 

#### $$\alpha_2^{new}$$ 的约束
　　上面通过求导的方式计算出的 $$\alpha_2^{new}$$ 是未经过约束的，即计算出来的值可能不满足约定的条件

$$
\begin{cases}
    0 \le \alpha_i \le C \\
    \alpha_1y_1 + \alpha_2y_2 = \zeta
\end{cases}\tag{2-15}
$$

这两个约束条件可以在二维平面上进行直观的展示

   [![alpha-constrains][img1]][img1]{:data-lightbox=&quot;smo&quot;}

上图横坐标为 $$\alpha_1$$，纵坐标为 $$\alpha_2$$，$$\alpha_2^{new}$$ 必须要在方框内和斜线上取值，其最大最小值一定是其交点，所以有 $$L \le \alpha_2^{new} \le H $$

1. 当 $$y_1 \ne y_2$$ 时，$$L = max\left(0,\alpha_2^{old} - \alpha_1^{old}\right)$$；$$H = min\left(C,C+\alpha_2^{old} - \alpha_1^{old}\right)$$
1. 当 $$y_1 = y_2$$ 时，$$L = max\left(0, \alpha_1^{old} + \alpha_2^{old} - C\right)$$；$$H = min\left(C,\alpha_2^{old} + \alpha_1^{old}\right)$$

所以 $$\alpha_2^{new}$$ 的约束如下：

$$
    \alpha_2^{new} = 
\begin{cases}
    H, \alpha_2^{new,unc} &gt; H\\
    \alpha_2^{new,unc}, L \le \alpha_2^{new,unc} \le H \\
    L, \alpha_2^{new,unc} &lt; L
\end{cases} \tag{2-16}
$$

其中，$$\alpha_2^{new,unc}$$ 表示 $$\alpha_2^{new}$$ 未经约束的结果（上述通过求导的结果）

#### 求解 $$\alpha_1^{new}$$

由公式 (2-8) 可知

$$
    \alpha_1^{new} = \alpha_1^{old} + y_1y_2(\alpha_2^{old} - \alpha_2^{new}) \tag{2-17}
$$ 

　　至此，通过公式 (2-14)，(2-16)，(2-17) 可以接出 $$\alpha_1^{new}$$ 和 $$\alpha_2^{new}$$，SMO 算法的核心逻辑已介绍完毕，后面将介绍如何选取变量 $$\alpha_1$$ 和 $$\alpha_2$$ 以及对 SVM 优化目标中的 $$b$$ 求值。

### SMO 变量选取

#### 第一个变量选择
　　第一个变量的选择称为外循环，首先遍历整个样本然后选择违反 KKT 条件的 $$\alpha_i$$ 作为第一个变量，其 KKT 条件如下：

$$
    \begin{aligned}
     \alpha_{i}=0 &amp; \Rightarrow y_i\left(w^{T} x_i+b\right) \geq 1 \\ 
     \alpha_{i}=C &amp; \Rightarrow y_i\left(w^{T} x_i+b\right) \leq 1 \\ 
     0&lt;\alpha_{i}&lt;C &amp; \Rightarrow y_i\left(w^{T} x_i+b\right)=1 
    \end{aligned}
$$

&gt;  一般而言，首选选择违反 $$ 0&lt;\alpha_{i}&lt;C  \Rightarrow y_i\left(w^{T} x_i+b\right)=1$$ 这个条件点

&gt;  如果支持向量都满足 KKT 条件，再选择 $$\alpha_{i}=0  \Rightarrow y_i\left(w^{T} x_i+b\right) \geq 1$$ 和 $$\alpha_{i}=C \Rightarrow y_i\left(w^{T} x_i+b\right) \leq 1 $$ 这两个条件点

#### 第二个变量选择
　　第二个变量选择的过程为内循环，选择 $$|E_1 - E_2|$$ 取得最大值的 $$\alpha_2$$
&gt; 如果内循环中找不到点能够使目标函数有足够的下降，则可遍历支持向量来做 $$\alpha_2$$

&gt; 如果所有支持向量均不能使得目标函数有足够的下降，则跳出循环，重新选择 $$\alpha_1$$

### SMO 阈值 $$b$$ 的计算

**1.　若 $$0 &lt; \alpha_1^{new} &lt; C$$，则**

由 $$y_1 = \left(\omega^Tx_1 + b\right) = \sum_{i=1}^{N} K_{i1}\alpha_iy_i + b$$ 得：

$$
    b_1^{new} = y_1 - \sum\limits_{i=3}^{N}K_{i1}\alpha_iy_i - K_{11}\alpha_1^{new}y_1  - K_{21}\alpha_2^{new}y_2\tag{4-1}
$$

而

$$
\begin{align*}
    y_1 - \sum\limits_{i=3}^{N}K_{i1}\alpha_iy_i  &amp;= y_1 - f(x_1) + K_{11}\alpha_1^{old}y_1 + K_{21}\alpha_2^{old}y_2 + b^{old} 
\end{align*}\tag{4-2}
$$

将 (4-2) 代入到 (4-1) 得：

$$
\begin{align*}
    b_1^{new} = &amp; y_1 - f(x_1) + K_{11}\alpha_1^{old}y_1 + K_{21}\alpha_2^{old}y_2 + b^{old} \\
    &amp;- \alpha_1^{new}y_1K_{11} - \alpha_2^{new}y_2K_{21}        
\end{align*}\tag{4-3}
$$

由 $$E_i = f(x_i) - y_i $$ 化简可得：

$$
\begin{align*}
   b^{new} =  b_{1}^{new}=-E_{1}-y_{1} K_{11}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{21}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}
\end{align*}\tag{4-4}
$$

**2.　若 $$0 &lt; \alpha_2^{new} &lt; C$$，则**

$$
   b^{new} =  b_{2}^{new}=-E_{2}-y_{1} K_{12}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{22}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}\tag{4-5}
$$

**3.　若同时满足 $$0 &lt; \alpha_i^{new} &lt; C$$，则**

$$
    b^{new} = b_1^{new} = b_2^{new}\tag{4-6}
$$

**4.　若同时不满足 $$ 0 &lt; \alpha_i^{new} &lt; C $$，则**

$$
    b^{new} = \frac{b_1^{new}  + b_2^{new}}{2} \tag{4-7}
$$

关于上述取值分析可参考：[SMO算法在更新参数b过程中的疑问][href2]

至此，SMO 算法剖析完毕。

### 总结
　　输入是 N 个样本 $$(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$$，其中 $$x_i$$ 为输入特征，$$y_i$$ 为样本分类（只能取 $$1$$ 或者 $$-1$$），输出是近似解 $$\alpha$$
&gt; 注：$$\alpha_i$$ 并不是只能取 $$1$$ 或 $$-1$$

求解步骤：

1. 取初值 $$\alpha = 0,t=0$$
1. 选择变量 $$\alpha_1^t$$ 和 $$\alpha_2^t$$，根据公式求解出 $$\alpha_2^{t+1}$$
1. 利用 $$\alpha_1^{t+1}$$ 和 $$\alpha_1^t,\alpha_2^t,\alpha_2^{t+1}$$ 的关系求解出 $$\alpha_1^{t+1}$$
1. 通过 $$\alpha_1^{t+1}$$ 和 $$\alpha_2^{t+1}$$ 的满足的 KKT 条件关系求出 $$b^{t+1}$$
1. 检查 $$E_i$$ 是否在允许的精度 $$e$$ 之内
1. 检查求出的 $$\alpha_1^{t+1}$$ 和  $$\alpha_2^{t+1}$$ 是否满足 KKT 条件
1. 如果上面两个条件都满足则返回 $$\alpha_1^{t+1}$$ 和 $$\alpha_2^{t+1}$$，否则跳转到第 2 步

　　SMO 算法可以实现对 SVM 的目标函数的快速优化，其推导过程是十分复杂的，所以需要有耐心将它一一进行剖析，但是 SMO 的求解步骤是十分清晰的，下一步将通过代码实现 SMO 算法。

[href1]: /2019/04/03/ml-svm/
[href2]: https://ask.julyedu.com/question/696


[img1]: /images/post/ml/smo-alpha-constrains.jpg</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="推荐" /><category term="SMO" /><category term="SVM" /><category term="机器学习" /><summary type="html">1996年，John Platt 发布一个称为 SMO（Sequential Minimal Optimization，序列最小优化）的强大算法，用于训练 SVM，该算法的核心思想是将原问题分解成多个小问题分别进行优化求解。</summary></entry><entry><title type="html">真正理解拉格朗日乘子法和 KKT 条件</title><link href="http://0.0.0.0:4800/2019/04/06/lagrange-kkt/" rel="alternate" type="text/html" title="真正理解拉格朗日乘子法和 KKT 条件" /><published>2019-04-06T00:00:00+00:00</published><updated>2019-04-06T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/06/lagrange-kkt</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/06/lagrange-kkt/">　　这篇博文以直观的方式讲解了拉格朗日乘子法和 KKT 条件，对偶问题等内容。

### 无约束优化

　　首先从无约束的优化问题讲起，一般就是要使一个表达式取到最小值：

$$
    min\ f(x)
$$

　　如果求 $$max\ f(x)$$ 也可以通过取反转化为求 $$min\ (−f(x))$$ 的问题，然后对它的每一个变量求求，然后让偏导为零，解方程组就行了。

   [![kkt][img1]][img1]{:data-lightbox=&quot;kkt&quot;}

　　如图可知，在极值点处一定满足 $$\frac{df(x)}{dx}=0$$（只是必要条件，比如 $$f(x)=x^3$$ 在 $$x=0$$ 处就不是极值点）然后对它进行求解，再代入验证是否真的是极值点就行了，对于有些问题可以直接通过这种方法求出解析解（如最小二乘法）。

　　但是也有很多问题解不出来或者很难解，所以就需要梯度下降法、牛顿法、坐标下降法之类的数值迭代算法了（感知机 、logistic 回归中用到）。

　　对于这些迭代算法就像下面这张图一样，我们希望找到其中的最小值，一个比较直观的想法是先找一个起点，然后不断向最低点靠近，就像把一个小球放到一个碗里一样。

   [![iter][img2]][img2]{:data-lightbox=&quot;kkt&quot;}

　　一开始要找一个起始点，然后确定走的方向和距离，最后还要知道什么时候停止，这三步中最难的是确定走的方向，因为走的慢点还可以接受，要是方向错了就找不到最小值了，所以走的距离可以简单的设为一个比较小的值，起始点可以随机选一个 $$(x_0,y_0)$$，然后是确定方向，一般选择 $$(x_0,y_0)$$ 处梯度的反方向，这是函数在这个点下降最快的方向（原因可以看[知乎][href1]中忆臻的回答），它是一个向量，然后它的大小就是走的距离，为了防止太大而走过头，导致不断在最小值附近来回震荡，所以需要乘上一个比较小的因子（称为学习率），最终的停止条件就是梯度的大小很接近于 0（在极值点处的梯度大小为 0），这种方法依靠梯度确定下降方向的方法叫做梯度下降法。

　　对 $$f(x)$$ 求极小值的流程就是：

1. 随机选定 $$x_0$$
1. 得到函数在 $$x_0$$ 的梯度，然后从 $$x_0$$ 向前走一步：$$x_0^{new0}=x_0^{old0}−\alpha\nabla{f(x)}$$
1. 重复第 2 步，直到梯度接近于 0（小于一个事先设定的很小的数），或者到达指定的迭代上限，如下图所示

   [![gradient-des][img3]][img3]{:data-lightbox=&quot;kkt&quot;}

    除了这种方法之外，其中第 2 步还可以这样做，将 $$x$$ 固定为常数，这样就变成只有一个变量的优化问题了，直接求导为 0 就可以得到最优点，向前走到 $$(x_0,y_1)$$ 处，然后固定 $$y_1$$, 对 $$x$$ 进行相同的操作，这种每次只优化一个变量的方法叫做坐标下降法，如下图所示

   [![coordlinate-des][img4]][img4]{:data-lightbox=&quot;kkt&quot;}

### 等式束优化

    进一步的，我们可能要在满足一定约束条件的情况下最小化目标函数，比如有一个等式约束：

$$
\begin{cases}
    min\ f(x)\\
    s.t.\ h(x) = 0
\end{cases}
$$

   [![extremum-constraint][img5]][img5]{:data-lightbox=&quot;kkt&quot;}

    该问题不能通过求 $$f(x)$$ 的极值点来解决，因为这个问题的解可能根本不是 $$min\ f(x)$$ 的解，那么还是要从问题本身去找线索：

    如图，其中的圆圈是指目标函数 $$f(x，y)$$ 投影在平面上的等值线，表示在同一个圆圈上，黑线是约束条件 $$h(x)=0$$ 的函数图像，可知，等值线与函数图像相交的点其实就是所有满足约束的点，那么极值点只有可能在等值线与函数图像相切的地方取到，因为如果在相交的地方取到，那么沿着 $$h(x)$$ 的图像往前走或者往后走，一定还有其它的等值线与它相交，也就是 $$f(x,y)$$ 的值还能变大和变小，所以交点不是极值点，只有相切的时候才有可能是极值点。在相切的地方 $$h(x)$$ 的梯度和 $$f(x,y)$$ 的梯度应该是在同一条直线上的。（这一点可以这么想，在切点处两个函数的梯度都与切平面垂直，所以在一条直线上）

    所以满足条件的极值点一定满足：$$∇f(x,y)=λ∇h(x,y)$$ ( $$λ=0$$ 是允许的，表示 $$f(x,y)$$ 本身的极值点刚好在切点上)，然后和原来的等式方程 $$h(x,y)=0$$ 联立，然后只要解出这个方程组，就可以得到问题的解析解了。当然也存在解不出来的情况，就需要用罚函数法之类的方法求数值解。

    为了方便和好记，就把原来的优化问题写成 $$f(x,y)+λh(x,y)$$ 的形式，然后分别对 $$λ,x,y$$ 求偏导，并令之等于 0，该方法称之为拉格朗日乘数法。

    如果有多个等式约束怎么办呢，如下图：

   [![extremum-multi-constraint][img6]][img6]{:data-lightbox=&quot;kkt&quot;}

    这里的平面和球面分别代表了两个约束 $$h_1(x)$$ 和 $$h_2(x)$$，那么这个问题的可行域就是它们相交的那个圆。这里蓝色箭头表示平面的梯度，黑色箭头表示球面的梯度，那么相交的圆的梯度就是它们的线性组合（只是直观上的），所以在极值点的地方目标函数的梯度和约束的梯度的线性组合在一条直线上。所以就满足：

$$
\begin{cases}
   \nabla f(x) = \lambda \sum_{i=1}^{2}{\mu_{i}\nabla h_i(x)}=\sum_{i=1}^{2}\lambda_{i}\nabla h_i(x)\\
h_1(x)=0\\
h_2(x)=0
\end{cases}
$$

    对于大于 2 个约束的情况也一样，令 $$L(x,λ)=f(x)+\sum_{i=1}^{n}λ_i∇h_i(x)$$ 然后分别对 $$x、λ$$ 求偏导并令它们为 0，这个可以看做是一种简记，或者是对偶问题，这个函数叫做拉格朗日函数。

### 不等式约束优化
    再进一步，如果问题中既有等式约束，又有不等式约束怎么办呢？对于：

$$
   \begin{cases}
   min\ f(x)\\
   s.t.\\ 
   \quad h(x) = 0\\
   \quad g(x) \le 0
   \end{cases}
$$

   当然也同样约定不等式是 $$\le$$，如果是 $$\ge$$ 只要取反就行了。对于这个问题先不看等式约束，对于不等式约束和目标函数如下图：

   [![inequation-constraint][img7]][img7]{:data-lightbox=&quot;kkt&quot;}

    阴影部分就是可行域，也就是说可行域从原来的一条线变成了一块区域。那么能取到极值点的地方可能有两种情况：

1. 还是在 $$h(x)$$ 和 等值线相切的地方
1. $$f(x)$$ 的极值点本身就在可行域里面

    因为如果不是相切，那么同样的，对任意一个在可行域中的点，如果在它附近往里走或者往外走，$$f(x)$$ 一般都会变大或者变小，所以绝大部分点都不会是极值点，除非这个点刚好在交界处，且和等值线相切，或者这个点在可行域内部，其本身就是 $$f(x)$$ 的极值点，如下图：

   [![inequation-extremum][img8]][img8]{:data-lightbox=&quot;kkt&quot;}

    对于右边的情况，不等式约束就变成等式约束了，对 $$f(x)+λh(x)+μg(x)$$ 用拉格朗日乘子法：

$$
   \begin{cases}
      \nabla f(x)+\lambda \nabla h(x)+\mu \nabla g(x) = 0\\
      h(x)=0\\
      g(x)=0\\
      \mu \geq 0
   \end{cases}
$$

    这里需要解释一下，为什么不是 $$μ \ne 0$$ 而是 $$\mu \ge 0$$，后面的约束比前面的更强，已知问题中的可行域是在 $$g(x)≤0$$ 一侧，而由上上个图可知 $$g(x)$$ 的梯度是指向大于 0 的一侧，也就为可行域相反的一侧，而求的问题是极小值，而 $$f(x)$$ 在交点处的梯度是指向可行域的一侧，也就是说两个梯度一定是相反的，所以也就可以确定这里的系数一定是大于 0 的，而等式约束由于不知道 $$h(x)$$ 的梯度方向，所以对它没有约束， 而 $$\mu = 0 $$ 是因为极值点可能刚好在 $$g(x)$$ 上。

    对于左边的情况，不等式约束就相当于没有，对 $$f(x)+\lambda h(x)$$ 用拉格朗日乘子法：

$$
   \begin{cases}
      \nabla f(x)+\lambda \nabla h(x)= 0\\
      h(x)=0\\
      g(x) \leq 0
   \end{cases}
$$

    最好把两种情况用同一组方程表示出来。对比一下两个问题，不同的是第一种情况中有 $$\mu \ge 0$$ 且 $$g(x)=0$$, 第二种情况 $$\mu = 0$$ 且 $$g(x) \le 0$$ ，综合两种情况，可以写成 $$\mu g(x)=0$$ 且 $$\mu \ge 0，g(x) \le 0$$：

$$
   \begin{cases}
      \nabla f(x)+\lambda \nabla h(x)+\mu \nabla g(x) = 0\\
         \mu g(x) = 0\\
         \mu \geq 0 \\
         h(x)=0\\
         g(x) \leq 0
   \end{cases}
$$

### KKT 条件
    上述不等式约束优化就是 KKT 条件，它的含义是这个优化问题的极值点一定满足这组方程组（不是极值点也可能会满足，但是不会存在某个极值点不满足的情况）它也是原来的优化问题取得极值的必要条件，解出来了极值点之后还是要代入验证的。但是因为约束比较多，情况比较复杂，KKT 条件并不是对于任何情况都是满足的。要满足 KKT 条件需要有一些规范性条件（Regularity conditions），就是要求约束条件的质量不能太差，常见的比如：

1. LCQ：如果 $$h(x)$$ 和 $$g(x)$$ 都是形如 $$Ax+b$$ 的仿射函数，那么极值一定满足 KKT 条件。
1. LICQ：起作用的 $$g(x)$$ 函数（$$g(x)$$ 相当于等式约束的情况）和 $$h(x)$$ 函数在极值点处的梯度线性无关，那么极值一定满足 KKT 条件。
1. Slater：如果优化问题是个凸优化问题，且至少存在一个点满足 $$h(x)=0$$ 和 $$g(x)=0$$，极值一定满足 KKT 条件，并且满足强对偶性质。

    这里的 Slater 条件比较重要，因为它可以推导出强对偶性质（比 KKT 条件还好）。它需要原问题是凸优化问题，所谓凸优化就是这个优化问题的优化函数是凸函数，并且可行域是凸集，可行域数凸集就要求其中的 $$h(x) \le 0$$ 的条件中 $$h(x)$$ 必须也是凸函数，而 $$g(x) \le 0$$ 中的 $$g(x)$$ 必须是 $$Ax+b$$ 形式的，也就是仿射函数（比如二维的情况，可行域就在 $$g(x)$$ 这条曲线上，那么 $$g(x)$$ 必须得是直线才能满足凸集的定义）。

    其它条件还有很多，可以看[维基百科][href2]。

    如果有多组等式约束 $$h_i(x)=0(i=1,..,n)$$, 和不等式约束 $$g_i(x) \ne 0(i=1,..,n)$$ 也是一样，只要做个线性组合就行了：

$$
   \begin{cases}
      \nabla f(x)+\sum_{i=1}^{n}\lambda_i \nabla h_i(x)+\sum_{i=1}^{n}\mu_i \nabla g_i(x) = 0\\
      \mu_i g(x)_i = 0\\
      \mu_i \geq 0\\
      h_i(x)=0\\
      g_i(x) \leq 0\\
      i = 1,2,...,n
   \end{cases}
$$

    问题到这里就大致解决了，KKT 条件虽然从理论上给出了极值的必要条件，但是一般实际解的时候直接方程也是很困难的（特别是约束很多的时候），一般也会采用罚函数法等数值方法。

### 对偶问题
    为了更好的解决这个优化问题，数学家还找到了它的对偶问题，找一个优化问题的对偶问题的一般因为是对偶问题比原问题更好解决，并且对偶问题的解和原问题是一样的，上面的拉格朗日函数也可以看做原问题的对偶问题。

    为了去掉问题中的约束，可以把它们作为惩罚项加到目标函数中 $$min_xf(x)+Mh(x)+Ng(x)$$ 其中 M, N 是两个很大的正数，在数值解法中可以直接这样做，这个就是罚函数法的思路。不过在理论推导时这样做是不严谨的，除非 M, N 为无穷大，可改写 $$L(x,μ,λ)=min_{x}max_{\mu,\lambda} f(x)+\lambda h(x)+\mu g(x)$$。这个式子可以这么理解，现在外层给定任意一个 $$x_0$$ 值，然后内层在给定的 $$x_0$$ 下优化那个函数，让它最小。然后外层选能够让内层得到的值最大的一个 $$x_0$$，得到的函数表达式就是：

$$
   L(x,\mu,\lambda)=
            \left\{\begin{matrix}
            f(x) &amp; (x \quad满足约束)\\
            \infty &amp; (x \quad不满足约束)\\ 
            \end{matrix}\right.
$$

    所以外层选的那个 $$x_0$$ 一定满足约束，否则，内层的 $$max$$ 的时候会让 $$\mu$$ 或者 $$\lambda$$ 为无穷大，外层不会选那些能让内层得到无穷大的 $$x$$ 值，这样改写就和原来的带约束形式完全一致了，但是形式不同。这样可以利用 $$max[min\ f(x)] \le min[max\ f(x)]$$ 这个公式（这个很好理解，$$min\ f(x) \le min[max\ f(x)]$$, 然后就有这个公式了），得到原问题的最小值的一个下界，就是:

$$
   min_{x}max_{\mu,\lambda}f(x) + \lambda h(x) + \mu g(x)  \geq  max_{\mu,\lambda}min_{x}f(x) + \lambda h(x) + \mu g(x)
$$

    前面的就是原函数，后面的是它的一个下界。那么为什么要这样做呢? 是因为后面的一定是一个凸规划（理论上证明了的），比较好解决。但是这个只是一个下界，它们之间还是有一定的差距。这个差距叫对偶误差（duality gap）。对偶误差如果为 0 其实是一个非常好的性质，表示可以直接求解后面的问题得到原问题的解，这种性质叫强对偶性质，否则就只是弱对偶。

    强对偶性质非常好，但是要求也很苛刻，比 KKT 条件要苛刻。如果问题满足强对偶一定也满足 KKT 条件，反之不一定。对于这类优化问题，KKT 条件、强对偶、规范性条件之间的关系是：

   [![kkt-rc-relation][img9]][img9]{:data-lightbox=&quot;kkt&quot;}


[href1]: https://www.zhihu.com/question/36301367
[href2]: https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions

[img1]: /images/post/ml/extremum-value-sketch.png
[img2]: /images/post/ml/extremum-iter.jpg
[img3]: /images/post/ml/gradient-des.jpg
[img4]: /images/post/ml/coordlinate-des.jpg
[img5]: /images/post/ml/extremum-constraint.png
[img6]: /images/post/ml/extremum-multi-constraint.png
[img7]: /images/post/ml/kkt-inequation-constraint.png
[img8]: /images/post/ml/kkt-extremum-inequation.png
[img9]: /images/post/ml/kkt-rc-relation.png</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="KKT" /><category term="拉格朗日乘子法" /><summary type="html">KKT 条件是解决最优化问题的时用到的一种方法。最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值。</summary></entry><entry><title type="html">支持向量机通俗导论（理解SVM的三层境界）</title><link href="http://0.0.0.0:4800/2019/04/03/ml-svm/" rel="alternate" type="text/html" title="支持向量机通俗导论（理解SVM的三层境界）" /><published>2019-04-03T00:00:00+00:00</published><updated>2019-04-03T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/03/ml-svm</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/03/ml-svm/"></content><author><name>Aiesst</name></author><category term="机器学习" /><category term="推荐" /><category term="机器学习" /><category term="SVM" /><summary type="html">支持向量机，因其英文名为support vector machine，故一般简称SVM，通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</summary></entry><entry><title type="html">机器学习-决策树-ID3</title><link href="http://0.0.0.0:4800/2019/03/28/ml-decision-tree-id3/" rel="alternate" type="text/html" title="机器学习-决策树-ID3" /><published>2019-03-28T00:00:00+00:00</published><updated>2019-03-28T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/03/28/ml-decision-tree-id3</id><content type="html" xml:base="http://0.0.0.0:4800/2019/03/28/ml-decision-tree-id3/">　　决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy = 系统的凌乱程度，使用算法ID3, C4.5和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。

　　决策树最经典的算法包括：ID3、C4.5以及CART算法，ID3与C4.5算法相似，C4.5在特征选择时选用的信息准则是信息增益比，而ID3用的是信息增益；因为信息增益偏向于选择具有较多可能取值的特征（例如，某一特征具有5个可能取值，其信息增益会比具有2个特征取值的信息增益大）。

### 准备

#### 信息熵

　　熵表示随机变量的不确定性，熵值越大表示随机变量含有的信息越少，变量的不确定性越大。

　　熵也是一个物理量和质量、温度、速度一样都是可以测定的，物理量的测定是需要参考物的，比如当测某个物体的质量时只需要计算该物体的重量为参考物的多少倍即可，比如参考物是 1KG，该物体的重量是它的 3 倍，那么该物体的质量为 3KG。

　　熵的测定也是一样的，不过熵表示不确定性那么选择的参考物为抛 1 个硬币（熵为 1）这种只有 2 种情况的不确定性，但是测量熵不是通过乘法来做的而是通过指数测量的，比如抛 3 个硬币（熵为 3）的情况不是 6 种而是 $$2^3 = 8$$ 种，它的熵为 $$log_2{8} = 3$$，再比如某个选择题的答案为 A B C D 中的一个，那么该题的熵为 $$log_2{4} = 2$$。即熵的一般公式为：

$$
    log_2{m}
$$

&gt; 注：m 表示事件的不确定个数

　　当事件为非等概率的时候，其每个事件的不确定个数为概率的倒数

 $$
    l(x_i) = log_2{\frac{1}{p(x_i)}} = - log_2{p(x_i)}
 $$

&gt; 注：这里的 $$\frac{1}{p(x_i)}$$ 表示 $$x_i$$ 的不确定个数

所以，样本集合的熵的计算公式如下：

$$
    H = - \sum_{i=1}^{n}{p(x_i)log_2{p(x_i)}} 
$$

$$p(x_i)$$ 表示 $$x_i$$ 在总样本中的概率，熵的单位是 bit(比特)

关于熵解释还可以参考知乎 [信息熵是什么？][href1]

#### 信息增益
　　信息增益在决策树算法中是用来选择特征的指标，信息增益越大，则这个特征的选择性越好，在概率中定义为：待分类的集合的熵和选定某个特征的条件熵之差（这里只的是经验熵或经验条件熵，由于真正的熵并不知道，是根据样本计算出来的），公式如下：

$$
    IG(X|Y) = H(Y) - H(Y|X)
$$

信息增益就是 （含所有特征的熵 — 缺少某特征的熵）

#### 决策树
　　决策树的结构是一个树状的，每一节点都是一个决策点，通过做不同的决策可以将样本分到最终叶子点的不同分类里面去，比如下图所示的一个要不要去约会的决策判断

[![decision-tree][img1]][img1]{:data-lightbox=&quot;decision-tree&quot;}


#### ID3 实现

#### 计算信息熵
```python
    def calcEntropy(dataSet):
    &quot;&quot;&quot;
    :param dataSet: 样本集合，最后一列为分类数据
    :return: 分类数据的信息熵
    &quot;&quot;&quot;
    labelsCount = {}
    for line in dataSet:
        # 分类标签
        label = line[-1]
        labelsCount[label] = labelsCount.get(label, 0) + 1
    entroy = 0.0
    for key in labelsCount:
        # 计算熵
        p = float(labelsCount[key]) / len(dataSet)
        entroy -= p * math.log(p, 2)
    return entroy
```

#### 划分数据集
```python
    def splitDataSet(dataSet, index, value):
    &quot;&quot;&quot;
    删除样本的指定列
    :param dataSet: 输入样本
    :param index: 列序号
    :param value: 样本中的列特征值等于 value 才有效
    :return: 取出样本中指定列特征等于 value 的所有样本，且删除掉指定的列
    &quot;&quot;&quot;
    result = []
    for feats in dataSet:
        if feats[index] == value:
            feat = feats[:index]
            feat.extend(feats[index + 1:])
            result.append(feat)
    return result
```

#### 选择最好的划分方式
```python
    def chooseBestFeat(dataSet):
        &quot;&quot;&quot;
        选择合适的特征列作为样本的划分标准，该特征为区分样本的最好的特征
        :param dataSet: 样本集合
        :return: 特征列序号
        &quot;&quot;&quot;
        # 最后一列为分类信息，不是特征
        featuresCount = len(dataSet[0]) - 1
        # 整体的信息熵
        entropy = calcEntropy(dataSet)
        bestInfoGain = 0.0
        bestFeature = -1
        for i in range(featuresCount):
            # 样本的某一列
            featVals = [ex[i] for ex in dataSet]
            # 过滤掉重复值
            uniquVals = set(featVals)
            subEntropy = 0.0
            for value in uniquVals:
                # 切分样本
                subDataSet = splitDataSet(dataSet, i, value)
                # 计算切分后的信息熵
                p = len(subDataSet) / float(len(dataSet))
                subEntropy += p * calcEntropy(subDataSet)
            # 整体的信息熵 - 子样本的信息熵
            # 差值越大说明信息增益越大
            infoGain = entropy - subEntropy
            if infoGain &gt; bestInfoGain:
                bestInfoGain = infoGain
                bestFeature = i
        return bestFeature
```

#### 简单的决策树
```python
    def classify(inputTree, featLabels, testVec):
        &quot;&quot;&quot;
        一个简单的决策树抉择
        :param inputTree: 决策树的结构，该结构为手动实现，通过上述的划分特征来获取各个决策点
        :param featLabels: 每个特征的名字
        :param testVec: 测试样本
        :return: 测试样本所属的分类
        &quot;&quot;&quot;
        key = inputTree.keys()[0]
        root = inputTree[key]
        # 当前测试的特征
        featIndex = featLabels.index(key)
        classLabel = -1
        for k in root.keys():
            # 抉择分类
            if testVec[featIndex] == k:
                # 决策点
                if type(root).__name__ == &quot;dict&quot;:
                    classLabel = classify(root[k], featLabels, testVec)
                # 终结点
                else:
                    classLabel = root[k]
        return classLabel
```

### 总结
　　决策树分类就是一个带有终止块的流程图，终止块代表了分类结果。处理数据时根据信息增益来找到最好的划分数据的方式，直到将所有同一类数据划分到一起为止，然后可以通过递归的方式来判断出测试数据所属的分类。

[href1]: https://www.zhihu.com/question/22178202/answer/49929786

[img1]: /images/post/ml/decision-tree.png</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="决策树" /><category term="ID3" /><summary type="html">决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。</summary></entry><entry><title type="html">算法-统计数字区间中 1 出现的次数</title><link href="http://0.0.0.0:4800/2018/09/20/algorithm-count-digits/" rel="alternate" type="text/html" title="算法-统计数字区间中 1 出现的次数" /><published>2018-09-20T00:00:00+00:00</published><updated>2018-09-20T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/09/20/algorithm-count-digits</id><content type="html" xml:base="http://0.0.0.0:4800/2018/09/20/algorithm-count-digits/">### 背景
[1,13] 区间中 1 出现的次数为 5 次分别为 1、10、11、12、13，现在求 [1,n] 区间中 1 出现的次数，推而广之能否求出 [1,n] 区间中任意数字出现的次数
[牛客网连接](https://www.nowcoder.com/practice/bd7f978302044eee894445e244c7eee6?tpId=13&amp;tqId=11184&amp;rp=2&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking)

### 分析
1. 对于每个位置来说都能把十进制的数分成两部分，比如对于 n=31415952</content><author><name>Aiesst</name></author><category term="算法" /><category term="Java" /><category term="数字" /><summary type="html">\[1,13] 区间中 1 出现的次数为 5 次分别为 1、10、11、12、13，现在求 [1,n] 区间中 1 出现的次数，推而广之能否求出 [1,n] 区间中任意数字出现的次数</summary></entry><entry><title type="html">算法-二叉树</title><link href="http://0.0.0.0:4800/2018/09/07/algorithm-bin-tree/" rel="alternate" type="text/html" title="算法-二叉树" /><published>2018-09-07T00:00:00+00:00</published><updated>2018-09-07T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/09/07/algorithm-bin-tree</id><content type="html" xml:base="http://0.0.0.0:4800/2018/09/07/algorithm-bin-tree/">### 背景
这是一个关于二叉树的一些算法题目，主要来源于 LeetCode

1. 判断同一颗树，[100. Same Tree](https://leetcode.com/problems/same-tree/description/)
   ```
    Input:    1         1
             / \       / \
            2   3     2   3

           [1,2,3],   [1,2,3]

    Output: true
   ```
1. 判断是否为子树，[572. Subtree of Another Tree](https://leetcode.com/problems/subtree-of-another-tree/description/)
   ```
   Given tree s:

          3
         / \
        4   5
       / \
      1   2
    Given tree t:
       4 
      / \
     1   2
    Return true, because t has the same structure and node values with a subtree of s.
   ```

1. 树的直径，树的两个节点的最大距离，[543. Diameter of Binary Tree](https://leetcode.com/problems/diameter-of-binary-tree/description/)
   ```
          1
         / \
        2   3
       / \     
      4   5  

    Return 3, which is the length of the path [4,2,1,3] or [5,2,1,3].
    Note: The length of path between two nodes is represented 
          by the number of edges between them.
   ```

1. 树的路径和，找出所有路径和为给定值得总量 [437. Path Sum III](https://leetcode.com/problems/path-sum-iii/description/)

   ```
   root = [10,5,-3,3,2,null,11,3,-2,null,1], sum = 8

          10
         /  \
        5   -3
       / \    \
      3   2   11
     / \   \
    3  -2   1
    Return 3. The paths that sum to 8 are:
    1.  5 -&gt; 3
    2.  5 -&gt; 2 -&gt; 1
    3. -3 -&gt; 11
   ```</content><author><name>Aiesst</name></author><category term="算法" /><category term="Java" /><category term="二叉树" /><summary type="html">树的逆序，BST转GreaterTree，判断同一颗树，判断是否为子树，Merge 两颗树，树的直径，树的序列化/反序列化等等...</summary></entry><entry><title type="html">算法-雨水问题</title><link href="http://0.0.0.0:4800/2018/09/05/algorithm-rain/" rel="alternate" type="text/html" title="算法-雨水问题" /><published>2018-09-05T00:00:00+00:00</published><updated>2018-09-05T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/09/05/algorithm-rain</id><content type="html" xml:base="http://0.0.0.0:4800/2018/09/05/algorithm-rain/">### 背景


1. 给定一个一维数组，求出两条边界的最大储水量值，[Container With Most Water](https://leetcode.com/problems/container-with-most-water/description/)


[![rain-trap][img2]][img2]{:data-lightbox=&quot;rain-trap&quot;}

   ```
    Input: [1,8,6,2,5,4,8,3,7]
    Output: 49
   ```

1. 给定一个一维数组代表边界高度求最大的储水量，[Trapping Rain Water](https://leetcode.com/problems/trapping-rain-water/description/)

[![rain-trap][img1]][img1]{:data-lightbox=&quot;rain-trap&quot;}

   ```
    Input: [0,1,0,2,1,0,1,3,2,1,2,1]
    Output: 6
   ```

1. 给定一个 mxn 的二维数组，求出其代表的容器的最大储水量，[Trapping Rain Water II](https://leetcode.com/problems/trapping-rain-water-ii/description/)

[![rain-trap][img3]][img3]{:data-lightbox=&quot;rain-trap&quot;}

[![rain-trap][img4]][img4]{:data-lightbox=&quot;rain-trap&quot;}

   ```
    Given the following 3x6 height map:
    [
        [1,4,3,1,3,2],
        [3,2,1,3,2,4],
        [2,3,3,2,3,1]
    ]

    Return 4.
   ```


### 算法
#### 两条边界储水量
该题可用双指针法求解，每次保留高度较高的那边，计算的时候按短边计算，详情参考 [Solution](https://leetcode.com/problems/container-with-most-water/solution/)

```java
    public int maxArea(int[] height) {
        if(height == null || height.length &lt; 2){
            return 0;
        }
        int ans =0,l=0,r=height.length-1;
        while (l&lt;r){
            // 短边法，找到 i,j 的储水量，更新最大值
            ans  = Math.max(ans,Math.min(height[l],height[r]) * (r-l));
            // 保留长边，下次迭代
            if(height[r] &gt; height[l]){
                l++;
            }else{
                r--;
            }
        }
        return ans;
    }

```

#### 一维数组储水量
该题用动态规划比较好理解,详情参考 [Solution](https://leetcode.com/problems/trapping-rain-water/solution/)

```java
    public int trap2(int[] heights){
        if(heights == null || heights.length == 0){
            return 0;
        }
        int[] leftMax  = new int[heights.length];
        int[] rightMax = new int[heights.length];
        leftMax[0] = heights[0];
        rightMax[heights.length-1] = heights[heights.length-1];
        for(int i=1;i&lt;heights.length;i++){
            // i 左边的最大边界
           leftMax[i] = Math.max(leftMax[i-1],heights[i]);
        }
        for(int j=heights.length-2;j&gt;=0;j--){
            // j 右边的最大边界
            rightMax[j] = Math.max(rightMax[j+1],heights[j]);
        }
        int ans = 0;
        for (int i = 0; i &lt; heights.length; i++) {
           // 用至该边界能储水的最大边界，减去该边界占的空间，剩下的就是能够储水的空间
           ans += Math.min(leftMax[i],rightMax[i]) - heights[i];
        }
        return ans;
    }
```
#### 二维数组储水量
该题用优先队列，详情参考 [Solution](https://leetcode.com/problems/trapping-rain-water-ii/discuss/89461/Java-solution-using-PriorityQueue)

```java
public class Solution {
     int[][] next = { {1, 0}, {0, 1}, {-1, 0}, {0, -1}};

    public int trapRainWater(int[][] heights) {
        if (heights == null || heights.length == 0 || heights[0].length == 0) {
            return 0;
        }
        boolean[][] mark = new boolean[heights.length][heights[0].length];
        // int[]，有三个值 i,j,高度
        // o1[2]-o2[2] 高度作为比较维度
        PriorityQueue&lt;int[]&gt; queue = new PriorityQueue&lt;&gt;(new Comparator&lt;int[]&gt;() {
            @Override
            public int compare(int[] o1, int[] o2) {
                return o1[2] - o2[2];
            }
        });

        // 先把最外层圈放入队列
        for (int i = 0; i &lt; heights.length; i++) {
            for (int j = 0; j &lt; heights[i].length; j++) {
                if (i == 0 || j == 0 || i == heights.length - 1 
                    || j == heights[i].length - 1) {
                    queue.add(new int[]{i, j, heights[i][j]});
                    mark[i][j]=true;
                }
            }
        }

        int sum = 0;
        while (!queue.isEmpty()) {
            int[] cell = queue.poll();
            for (int k = 0; k &lt; next.length; k++) {
                int ti = cell[0] + next[k][0];
                int tj = cell[1] + next[k][1];
                if (ti &lt; 0 || tj &lt; 0 || ti &gt;= heights.length
                     || tj &gt;= heights[0].length || mark[ti][tj]) {
                    continue;
                }
                // cell 是当前外围的最低点
                // 由于是由外向内遍历的，所以当前点为墙，ti,tj 指向的是内部
                // 计算储水量，然后累加
                sum += Math.max(0, cell[2] - heights[ti][tj]);
                mark[ti][tj] = true;
                // 因为要缩小一圈围墙，所以要取较大值，才能顶掉里面的值
                queue.add(new int[]{ti, tj, Math.max(cell[2], heights[ti][tj])});
            }
        }
        return sum;
    }
}
```



[img1]: /images/post/algorithm/rain-trap-1.png
[img2]: /images/post/algorithm/rain-trap-2.png
[img3]: /images/post/algorithm/rain-trap-3.png
[img4]: /images/post/algorithm/rain-trap-4.png</content><author><name>Aiesst</name></author><category term="算法" /><category term="Java" /><category term="雨水" /><summary type="html">这是一个在 Leetcode 上面的一些雨水容量方面的题，做一个适当的总结</summary></entry></feed>