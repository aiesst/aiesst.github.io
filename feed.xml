<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://0.0.0.0:4800/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4800/" rel="alternate" type="text/html" /><updated>2022-02-28T03:17:47+00:00</updated><id>http://0.0.0.0:4800/feed.xml</id><title type="html">Aiesst</title><subtitle>Aiesst的个人博客</subtitle><author><name>Aiesst</name></author><entry><title type="html">机器学习-Adaboost算法</title><link href="http://0.0.0.0:4800/2019/04/13/ml-adaboost/" rel="alternate" type="text/html" title="机器学习-Adaboost算法" /><published>2019-04-13T00:00:00+00:00</published><updated>2019-04-13T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/13/ml-adaboost</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/13/ml-adaboost/">　　Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。

　　Adaboost 的算法思想是</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="Adaboost" /><summary type="html">Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。</summary></entry><entry><title type="html">SMO 算法的代码实现</title><link href="http://0.0.0.0:4800/2019/04/12/ml-smo-py/" rel="alternate" type="text/html" title="SMO 算法的代码实现" /><published>2019-04-12T00:00:00+00:00</published><updated>2019-04-12T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/12/ml-smo-py</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/12/ml-smo-py/">　　SMO 是解决 SVM 中目标函数优化的一个快速的算法，本文通过 Python 代码实现了该算法，通过将原算法公式和代码进行一一比对让读者更能理会整个算法原理和实现步骤。

　　如果对文中的相关公式不了解请参考另一篇理论文章 [SMO 算法超详细解析][href2]

## 准备

本算法实现参考于《机器学习实战》，相关的数据资源请自行下载
&gt; [https://pan.baidu.com/s/1Gc7BDmNyBfGQlfVvhzyZFw][href1] 提取码：ywuh 

本文是基于 ```Python``` 来实现的整个算法，且依赖于 ```numpy```

本文的测试数据集在 ch06 文件下面的几个 txt 文件，这些测试文件的数据都是标准的二分类数据

   [![svm-test-set][img1]][img1]{:data-lightbox=&quot;smo&quot;}

## SMO 功能函数
### 加载数据
　　将上图中的 txt 测试数据加载到内存中，并生成指定的矩阵格式，其中特征数据赋值给了 X 矩阵，分类数据赋值给了 Y 矩阵
```python
def loadDataSet(fileName):
    &quot;&quot;&quot;
    加载文本数据
    :param fileName:
    :return:
    &quot;&quot;&quot;
    X = []
    Y = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = line.strip().split(&apos;\t&apos;)
        X.append([float(lineArr[0]), float(lineArr[1])])
        Y.append(float(lineArr[2]))
    # 分别转成矩阵，其中分类矩阵转置成一列
    return mat(X), mat(Y).T
```

### 注入数据
将一些基础数据通过构造函数注入进行注入
```python
class SMO:
    def __init__(self, X, Y, C, e, gaussDelta=1.3):
        &quot;&quot;&quot;
        初始化构造函数，注入训练样本，常量，容错率
        :param X: 样本特征
        :param Y: 样本分类，只能取 {1,-1}
        :param C: 常量
        :param e: 容错率
        :param gaussDetla: 高斯核函数的分母 delta 值
        &quot;&quot;&quot;
        self.X = X
        self.Y = Y
        self.C = C
        self.tol = e
        self.N = shape(X)[0]
        self.alphas = mat(zeros((self.N, 1)))
        self.b = 0
        self.eCache = mat(zeros((self.N, 2)))
        self.K = mat(zeros((self.N, self.N)))
        for i in range(self.N):
            self.K[:, i] = self.kernelGauss(self.X, self.X[i, :], gaussDelta)
```
### 高斯核

上述代码的最后有一行进行了高斯核处理，并将处理结果 $$K{ij}$$ 进行了缓存：

$$
K(x, y)=\exp \left(-\frac{\|x-y\|^{2}}{2 \sigma^{2}}\right)\tag{2-1}
$$

通过如下代码便可以实现高斯核，同时通过 ```calcKernel``` 方法直接返回了缓存的 $$K_{i,j}$$ 结果
```python
   def kernelGauss(self, X, Y, delta):
        &quot;&quot;&quot;
        计算高斯核函数值
        :param delta:
        :return:
        &quot;&quot;&quot;
        m, n = shape(X)
        k = mat(zeros((m, 1)))
        for j in range(m):
            diff = X[j, :] - Y
            k[j] = diff * diff.T
        return exp(-k / (2 * math.pow(delta, 2)))
    
     def calcKernel(self, i, j):
        &quot;&quot;&quot;
        这里直接返回的之前缓存的核函数值
        :param i:
        :param j:
        :return:
        &quot;&quot;&quot;
        return self.K[i, j]
```

### 计算 $$E_i$$
$$E_i$$ 表示了预测值与真实值的差，其计算方法如下：

$$
    E_i = f(x_i) - y_i =\sum_{j=1}^{N} \alpha_{j} y_{j} K_{ij}+b - y_i\tag{2-2}
$$


```python
  def calcEi(self, i):
        &quot;&quot;&quot;
        计算 f(x_i) - y_i
        :param i: 索引
        :return: 预测值和真实值的差值
        &quot;&quot;&quot;
        aiyi = multiply(self.alphas, self.Y)
        ki = self.K[:, i]
        fxi = float(aiyi.T * ki) + self.b
        ei = fxi - float(self.Y[i])
        return ei
```

### 选择第二个变量 $$\alpha_j$$
由于第二个变量的选择比较麻烦，所以将其单独提取出来

```python
    def selectJ(self, i, ei):
        &quot;&quot;&quot;
        选择 |Ei - Ej| 取最大值的时候的 j,Ej，要求 Ej 是之前迭代的，否者返回随机选取的 j,Ej
        :param i: 第一个变量
        :param ei: 第一个变量的 Ei
        :return: 第二个变量的 j,Ej
        &quot;&quot;&quot;
        j = -1
        maxDeltaE = 0
        ej = 0
        self.eCache[i] = [1, ei]
        # 要求选择的 Ej 必须是之前迭代过的，否则返回随机值
        validEcacheList = nonzero(self.eCache[:, 0].A)[0]
        if len(validEcacheList) &gt; 0:
            for k in validEcacheList:
                if k == i:
                    continue
                ek = self.calcEi(k)
                deltaE = abs(ei - ek)
                if deltaE &gt; maxDeltaE:
                    maxDeltaE = deltaE
                    ej = ek
                    j = k
            return j, ej
        else:
            j = self.selectJRand(i, self.N)
            ej = self.calcEi(j)
            return j, ej

    def selectJRand(self, i, n):
        &quot;&quot;&quot;
        随机选择第二个变量
        :param i:
        :param n:
        :return:
        &quot;&quot;&quot;
        j = i
        while j == i:
            j = int(random.uniform(0, n))
        return j

    def updateEi(self, i):
        &quot;&quot;&quot;
        更新 Ei 的缓存
        :param i:
        :return:
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        self.eCache[i] = [1, ei]
```

## SMO 核心处理
### $$\alpha$$ 更新
#### $$\alpha_2$$ 的更新

$$
    \alpha_2^{new,unc}=\alpha_2^{old}+\frac{y_2(E_1-E_2)}{\eta}
    \tag{2-3}
$$

其中，$$\alpha_2^{new}$$ 表示本次迭代的计算值，$$\alpha_2^{old}$$ 为上一次的迭代值 &lt;br/&gt;
　　$$E_i = f(x_i) - y_i$$ 表示预测值与真实值的差 &lt;br/&gt;
　　$$\eta=K_{11}+K_{22}-2K_{12} $$
$$

$$
    \alpha_2^{new} = 
\begin{cases}
    H, \alpha_2^{new,unc} &gt; H\\
    \alpha_2^{new,unc}, L \le \alpha_2^{new,unc} \le H \\
    L, \alpha_2^{new,unc} &lt; L
\end{cases} \tag{2-4}
$$

代码实现，用 ```alphas[j]``` 表示 $$\alpha_2$$
```python
    eta = self.calcKernel(i, i) + self.calcKernel(j, j) - 2 * self.calcKernel(i, j)
    ajOld = self.alphas[j].copy()
    if self.Y[i] != self.Y[j]:
        L = max(0, ajOld - aiOld)
        H = min(self.C, self.C + ajOld - aiOld)
    else:
        L = max(0, aiOld + ajOld - self.C)
        H = min(self.C, aiOld + ajOld)
    self.alphas[j] = ajOld + self.Y[j] * (ei - ej) / eta
    self.alphas[j] = self.truncateAlpha(self.alphas[j], H, L)
```
其中 ```self.truncateAlpha(self.alphas[j],H,L)``` 为 $$\alpha_j$$ 的约束

```python
    def truncateAlpha(self, aj, H, L):
        &quot;&quot;&quot;
        对 Aj 进行截取，只能在 H L 之内
        :param aj:
        :param H:
        :param L:
        :return:
        &quot;&quot;&quot;
        if aj &gt; H:
            return H
        elif aj &lt; L:
            return L
        else:
            return aj
```
#### $$\alpha_1$$ 的更新
$$
    \alpha_{1}^{n e w}=\alpha_{1}^{o l d}+y_{1} y_{2}\left(\alpha_{2}^{o l d}-\alpha_{2}^{n e w}\right)\tag{2-5}
$$

代码实现，用 ```alphas[i]``` 表示 $$\alpha_1$$

```python
        aiOld = self.alphas[i].copy()
        self.alphas[i] = aiOld + self.Y[i] * self.Y[j] * (ajOld - self.alphas[j])
```

### $$b$$ 的更新
1.　若 $$0 &lt; \alpha_1^{new} &lt; C$$，则

$$
   b^{new} =  b_{1}^{new}=-E_{1}-y_{1} K_{11}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{21}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}\tag{2-6}
$$


2.　若 $$0 &lt; \alpha_2^{new} &lt; C$$，则

$$
   b^{new} =  b_{2}^{new}=-E_{2}-y_{1} K_{12}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{22}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}\tag{2-7}
$$

3.　若同时满足 $$0 &lt; \alpha_i^{new} &lt; C$$，则

$$
    b^{new} = b_1^{new} = b_2^{new}\tag{2-8}
$$

4.　若同时不满足 $$ 0 &lt; \alpha_i^{new} &lt; C $$，则

$$
    b^{new} = \frac{b_1^{new}  + b_2^{new}}{2} \tag{2-9}
$$

代码实现
```python
        b1 = -ei - self.Y[i] * self.calcKernel(i, i) * (self.alphas[i] - aiOld) \
            - self.Y[j] * self.calcKernel(j, i) * (self.alphas[j] - ajOld) + self.b

        b2 = -ej - self.Y[j] * self.calcKernel(i, j) * (self.alphas[i] - aiOld) \
            - self.Y[j] * self.calcKernel(j, j) * (self.alphas[j] - ajOld) + self.b

        if 0 &lt; self.alphas[j] &lt; self.C:
            self.b = b1
        elif 0 &lt; self.alphas[i] &lt; self.C:
            self.b = b2
        else:
            self.b = (b1 + b2) / 2.0
```

### $$\alpha$$ 和 $$b$$ 更新代码

```python
    def updateAlphaB(self, i, e=0.00001):
        &quot;&quot;&quot;
        利用 SMO 算法优化一次 alpha_i, alpha_j, b
        :param i: 训练样本索引
        :param e: 最小更新步长
        :return: 更新成功返回 1，失败返回 0
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        # 选择那些在容错率之外的样本作为第一个变量
        if ((self.Y[i] * ei &lt; -self.tol) and (self.alphas[i] &lt; self.C)) or \
                ((self.Y[i] * ei &gt; self.tol) and (self.alphas[i] &gt; 0)):
            j, ej = self.selectJ(i, ei)
            aiOld = self.alphas[i].copy()
            ajOld = self.alphas[j].copy()
            if self.Y[i] != self.Y[j]:
                L = max(0, ajOld - aiOld)
                H = min(self.C, self.C + ajOld - aiOld)
            else:
                L = max(0, aiOld + ajOld - self.C)
                H = min(self.C, aiOld + ajOld)
            if L == H:
                print(&quot;L == H&quot;)
                return 0
            eta = self.calcKernel(i, i) + self.calcKernel(j, j) - 2 * self.calcKernel(i, j)
            # eta 类似于二阶导数值，只有当它 大于 0 才能取最小值
            if eta &lt;= 0:
                print(&quot;eta &lt;= 0&quot;)
                return 0
            # 计算 alpha_j 并截取在[H,L]之内
            self.alphas[j] = ajOld + self.Y[j] * (ei - ej) / eta
            self.alphas[j] = self.truncateAlpha(self.alphas[j], H, L)
            self.updateEi(j)
            if abs(self.alphas[j] - ajOld) &lt; e:
                print(&quot;j not moving enough&quot;)
                return 0
            self.alphas[i] = aiOld + self.Y[i] * self.Y[j] * (ajOld - self.alphas[j])
            self.updateEi(i)

            # 更新 b 的值
            b1 = -ei - self.Y[i] * self.calcKernel(i, i) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, i) * (self.alphas[j] - ajOld) + self.b

            b2 = -ej - self.Y[j] * self.calcKernel(i, j) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, j) * (self.alphas[j] - ajOld) + self.b

            if 0 &lt; self.alphas[j] &lt; self.C:
                self.b = b1
            elif 0 &lt; self.alphas[i] &lt; self.C:
                self.b = b2
            else:
                self.b = (b1 + b2) / 2.0
            return 1
        else:
            return 0

```

### 训练样本
训练样本主要是从样本的非边界值和所有值来回进行选取

```python
    def train(self, maxIter):
        &quot;&quot;&quot;
        训练样本
        :param maxIter: 最大迭代次数
        :return: 训练好的 b,alphas
        &quot;&quot;&quot;
        iter = 0
        entireSet = True
        alphaPairsChanged = 0
        # 在所有值和非边界值上面来回切换选取变量
        while (iter &lt; maxIter) and ((alphaPairsChanged &gt; 0) or entireSet):
            alphaPairsChanged = 0
            # 遍历所有值，更新那些没有迭代过的数据
            if entireSet:
                for i in range(self.N):
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;fullSet, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                    iter += 1
            # 遍历非边界值
            else:
                # 在 alphas 中取出大于 0 小于 c 的索引值
                # 即更新那些之前迭代过的 alpha_i alpha_j
                nonBoundIs = nonzero((self.alphas.A &gt; 0) * (self.alphas.A &lt; self.C))[0]
                for i in nonBoundIs:
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;non-bound, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                iter += 1
            if entireSet:
                entireSet = False
            elif alphaPairsChanged == 0:
                entireSet = True
            print(&quot;iteration number: %d&quot; % iter)
        return self.b, self.alphas
```

## 样本测试
这里使用了两组样本，其中 ```testSetRBF.txt``` 为训练样本，```testSetRBF2.txt``` 为测试样本
```python
if __name__ == &apos;__main__&apos;:
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF.txt&quot;)
    smo = SMO(X, Y, 200, 0.0001)
    b, alphas = smo.train(10000)
    # 支持向量即 alphas 大于 0 对应的那些有效的样本向量，这些向量是落在 SVM 的边界上面的
    # 支持向量的索引
    svIndices = nonzero(smo.alphas.A &gt; 0)[0]
    # 支持向量特征
    xSv = X[svIndices]
    # 支持向量分类
    ySv = Y[svIndices]
    print(&quot;there are %d Support Vectors&quot; % shape(xSv)[0])
    m, n = shape(X)
    errorCount = 0
    delta = 1.3
    for i in range(m):
        # 映射到核函数值
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1
    # 训练样本误差
    print(&quot;the training error rate is : %f&quot; % (float(errorCount / m)))

    errorCount = 0
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF2.txt&quot;)
    m, n = shape(X)
    for i in range(m):
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1

    # 测试样本误差
    print(&quot;the test error rate is : %f&quot; % (float(errorCount / m)))
```
最终运行的效果截图

   [![svm-test][img2]][img2]{:data-lightbox=&quot;smo&quot;}
## 总结
　　SMO 算法的实现过程并不复杂，主要处理了核函数，变量$$\alpha_1,\alpha_2$$的选取，$$\alpha,b$$ 的更新，样本训练的终止条件等问题&lt;br/&gt;
　　核函数主要使用了高斯核，当然也可以替换成其它的核函数。&lt;br/&gt;
　　$$\alpha_1$$ 变量的选取是通过容错率 ```self.tol``` 来进行抉择的，主要选择那些在容错率范围之外的数据来作为 $$\alpha_1$$。&lt;br/&gt;
　　$$\alpha_2$$ 变量的选取是当 $$|E_1 - E_2|$$ 取最大值的时候对应的变量。&lt;br/&gt;
　　样本训练的终止条件通过最大迭代次数、更新是否成功、完整集训练等标志来确定的。

## 附录
### 完整代码
文件 ```smo.py```

```python
from numpy import *
class SMO:
    def __init__(self, X, Y, C, e, gaussDelta=1.3):
        &quot;&quot;&quot;
        初始化构造函数，注入训练样本，常量，容错率
        :param X: 样本特征
        :param Y: 样本分类，只能取 {1,-1}
        :param C: 常量
        :param e: 容错率
        &quot;&quot;&quot;
        self.X = X
        self.Y = Y
        self.C = C
        self.tol = e
        self.N = shape(X)[0]
        self.alphas = mat(zeros((self.N, 1)))
        self.b = 0
        self.eCache = mat(zeros((self.N, 2)))
        self.K = mat(zeros((self.N, self.N)))
        for i in range(self.N):
            self.K[:, i] = self.kernelGauss(self.X, self.X[i, :], gaussDelta)

    def calcEi(self, i):
        &quot;&quot;&quot;
        计算 f(x_i) - y_i
        :param i: 索引
        :return: 预测值和真实值的差值
        &quot;&quot;&quot;
        aiyi = multiply(self.alphas, self.Y)
        ki = self.K[:, i]
        fxi = float(aiyi.T * ki) + self.b
        ei = fxi - float(self.Y[i])
        return ei

    def selectJ(self, i, ei):
        &quot;&quot;&quot;
        选择 |Ei - Ej| 取最大值的时候的 j,Ej，要求 Ej 是之前迭代的，否者返回随机选取的 j,Ej
        :param i: 第一个变量
        :param ei: 第一个变量的 Ei
        :return: 第二个变量的 j,Ej
        &quot;&quot;&quot;
        j = -1
        maxDeltaE = 0
        ej = 0
        self.eCache[i] = [1, ei]
        validEcacheList = nonzero(self.eCache[:, 0].A)[0]
        if len(validEcacheList) &gt; 0:
            for k in validEcacheList:
                if k == i:
                    continue
                ek = self.calcEi(k)
                deltaE = abs(ei - ek)
                if deltaE &gt; maxDeltaE:
                    maxDeltaE = deltaE
                    ej = ek
                    j = k
            return j, ej
        else:
            j = self.selectJRand(i, self.N)
            ej = self.calcEi(j)
            return j, ej

    def selectJRand(self, i, n):
        &quot;&quot;&quot;
        随机选择第二个变量
        :param i:
        :param n:
        :return:
        &quot;&quot;&quot;
        j = i
        while j == i:
            j = int(random.uniform(0, n))
        return j

    def updateEi(self, i):
        &quot;&quot;&quot;
        更新 Ei 的缓存
        :param i:
        :return:
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        self.eCache[i] = [1, ei]

    def updateAlphaB(self, i, e=0.00001):
        &quot;&quot;&quot;
        利用 SMO 算法优化一次 alpha_i 和 alpha_j
        :param i:
        :param e:
        :return:
        &quot;&quot;&quot;
        ei = self.calcEi(i)
        # 选择那些在容错率之外的样本作为第一个变量
        if ((self.Y[i] * ei &lt; -self.tol) and (self.alphas[i] &lt; self.C)) or \
                ((self.Y[i] * ei &gt; self.tol) and (self.alphas[i] &gt; 0)):
            j, ej = self.selectJ(i, ei)
            aiOld = self.alphas[i].copy()
            ajOld = self.alphas[j].copy()
            if self.Y[i] != self.Y[j]:
                L = max(0, ajOld - aiOld)
                H = min(self.C, self.C + ajOld - aiOld)
            else:
                L = max(0, aiOld + ajOld - self.C)
                H = min(self.C, aiOld + ajOld)
            if L == H:
                print(&quot;L == H&quot;)
                return 0
            eta = self.calcKernel(i, i) + self.calcKernel(j, j) - 2 * self.calcKernel(i, j)
            # eta 类似于二阶导数值，只有当它 大于 0 才能取最小值
            if eta &lt;= 0:
                print(&quot;eta &lt;= 0&quot;)
                return 0
            # 计算 alpha_j 并截取在[H,L]之内
            self.alphas[j] = ajOld + self.Y[j] * (ei - ej) / eta
            self.alphas[j] = self.truncateAlpha(self.alphas[j], H, L)
            self.updateEi(j)
            if abs(self.alphas[j] - ajOld) &lt; e:
                print(&quot;j not moving enough&quot;)
                return 0
            self.alphas[i] = aiOld + self.Y[i] * self.Y[j] * (ajOld - self.alphas[j])
            self.updateEi(i)

            # 更新 b 的值
            b1 = -ei - self.Y[i] * self.calcKernel(i, i) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, i) * (self.alphas[j] - ajOld) + self.b

            b2 = -ej - self.Y[j] * self.calcKernel(i, j) * (self.alphas[i] - aiOld) \
                 - self.Y[j] * self.calcKernel(j, j) * (self.alphas[j] - ajOld) + self.b

            if 0 &lt; self.alphas[j] &lt; self.C:
                self.b = b1
            elif 0 &lt; self.alphas[i] &lt; self.C:
                self.b = b2
            else:
                self.b = (b1 + b2) / 2.0
            return 1
        else:
            return 0

    def truncateAlpha(self, aj, H, L):
        &quot;&quot;&quot;
        对 Aj 进行截取，只能在 H L 之内
        :param aj:
        :param H:
        :param L:
        :return:
        &quot;&quot;&quot;
        if aj &gt; H:
            return H
        elif aj &lt; L:
            return L
        else:
            return aj

    def calcKernel(self, i, j):
        &quot;&quot;&quot;
        这里直接返回的之前缓存的核函数值
        :param i:
        :param j:
        :return:
        &quot;&quot;&quot;
        return self.K[i, j]

    def kernelGauss(self, X, Y, delta):
        &quot;&quot;&quot;
        计算高斯核函数值
        :param delta:
        :return:
        &quot;&quot;&quot;
        m, n = shape(X)
        k = mat(zeros((m, 1)))
        for j in range(m):
            diff = X[j, :] - Y
            k[j] = diff * diff.T
        return exp(-k / (2 * math.pow(delta, 2)))

    def train(self, maxIter):
        &quot;&quot;&quot;
        训练样本
        :param maxIter: 最大迭代次数
        :return: 训练好的 b,alphas
        &quot;&quot;&quot;
        iter = 0
        entireSet = True
        alphaPairsChanged = 0
        # 在所有值和非边界值上面来回切换选取变量
        while (iter &lt; maxIter) and ((alphaPairsChanged &gt; 0) or entireSet):
            alphaPairsChanged = 0
            # 遍历所有值
            if entireSet:
                for i in range(self.N):
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;fullSet, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                    iter += 1
            # 遍历非边界值
            else:
                # 在 alphas 中取出大于 0 小于 c 的索引值
                nonBoundIs = nonzero((self.alphas.A &gt; 0) * (self.alphas.A &lt; self.C))[0]
                for i in nonBoundIs:
                    alphaPairsChanged += self.updateAlphaB(i)
                    print(&quot;non-bound, iter: %d i: %d, pairs changed %d&quot; % (iter, i, alphaPairsChanged))
                iter += 1
            if entireSet:
                entireSet = False
            elif alphaPairsChanged == 0:
                entireSet = True
            print(&quot;iteration number: %d&quot; % iter)
        return self.b, self.alphas
```

文件 ```test.py```
```python
from smo import *
from numpy import *

def loadDataSet(fileName):
    &quot;&quot;&quot;
    加载文本数据
    :param fileName:
    :return:
    &quot;&quot;&quot;
    X = []
    Y = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = line.strip().split(&apos;\t&apos;)
        X.append([float(lineArr[0]), float(lineArr[1])])
        Y.append(float(lineArr[2]))
    # 分别转成矩阵，其中分类矩阵转置成一列
    return mat(X), mat(Y).T


if __name__ == &apos;__main__&apos;:
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF.txt&quot;)
    smo = SMO(X, Y, 200, 0.0001)
    b, alphas = smo.train(10000)
    # 支持向量的索引
    svIndices = nonzero(smo.alphas.A &gt; 0)[0]
    # 支持向量特征
    xSv = X[svIndices]
    # 支持向量分类
    ySv = Y[svIndices]
    print(&quot;there are %d Support Vectors&quot; % shape(xSv)[0])
    m, n = shape(X)
    errorCount = 0
    delta = 1.3
    for i in range(m):
        # 映射到核函数值
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1
    # 训练样本误差
    print(&quot;the training error rate is : %f&quot; % (float(errorCount / m)))

    errorCount = 0
    X, Y = loadDataSet(&quot;../source/ch06/testSetRBF2.txt&quot;)
    m, n = shape(X)
    for i in range(m):
        kernelEval = smo.kernelGauss(xSv, X[i, :], delta)
        predict = kernelEval.T * multiply(ySv, smo.alphas[svIndices]) + b
        if sign(predict) != sign(Y[i]):
            errorCount += 1

    # 测试样本误差
    print(&quot;the test error rate is : %f&quot; % (float(errorCount / m)))
```
[href1]: https://pan.baidu.com/s/1Gc7BDmNyBfGQlfVvhzyZFw
[href2]: /2019/04/10/ml-svm-smo/

[img1]: /images/post/ml/svm-test-set.jpg
[img2]: /images/post/ml/svm-test.jpg</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="SVM" /><category term="SMO" /><category term="Python" /><summary type="html">SMO 是解决 SVM 中目标函数优化的一个快速的算法，本文通过 Python 代码实现了该算法，通过将原算法公式和代码进行一一比对让读者更能理会整个算法原理和实现步骤。</summary></entry><entry><title type="html">SMO 算法超详细解析</title><link href="http://0.0.0.0:4800/2019/04/10/ml-svm-smo/" rel="alternate" type="text/html" title="SMO 算法超详细解析" /><published>2019-04-10T00:00:00+00:00</published><updated>2019-04-10T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/10/ml-svm-smo</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/10/ml-svm-smo/">　　1996年，John Platt 发布一个称为 SMO（Sequential Minimal Optimization，序列最小优化）的强大算法，用于训练 SVM，该算法的核心思想是将原问题分解成多个小问题分别进行优化求解，即 SMO 算法是为了解决 SVM 中的优化目标函数。

　　本文对于 SMO 算法进行了非常详细的剖析，建议读者对里面的公式推导进行亲自的演算，本文需要 SVM 的相关基础，如果对于 SVM 不熟悉可以参考 [支持向量机通俗导论（理解SVM的三层境界）][href1]。

### 优化目标

SVM 的优化目标函数：

$$
\begin{split}
    \mathop{min}\limits_{\vec{\alpha}} \Psi(\vec{\alpha}) = \begin{cases}
        \underbrace{ min }_{\alpha}  \frac{1}{2} \sum\limits_{i=1}^{N} \sum\limits_{j=1}^{N} \alpha_i\alpha_jy_iy_jK(x_i,x_j) - \sum\limits_{i=1}^{N}\alpha_i\\
        s.t. \; \sum\limits_{i=1}^{N}\alpha_iy_i = 0 \\
        0 \le \alpha_i \le C
    \end{cases}
\end{split}\tag{1-1}
$$

其中，$$x_i$$ 表示样本特征&lt;br/&gt;
　　$$y_i$$ 表示样本标签，且 $$y_i \in \{-1,1\}$$ &lt;br/&gt;
　　$$\alpha_i$$ 为要求解的参数 &lt;br/&gt;
　　$$C$$ 为惩罚系数（自己设定）

### SMO 算法剖析
　　SMO 算法的基本思想是将原问题求解 $$(\alpha_1,\alpha_2,...,\alpha_N)$$ 这 $$N$$ 个参数的问题分解成多个子二次规划的问题分别求解，每个子问题只需要求解其中的 2 个参数，每次通过启发式选择两个变量进行优化，不断循环，直到达到函数的最优值。

#### 选择 $$\alpha_1$$ $$\alpha_2$$ 为变量
　　将 $$\Psi(\vec{\alpha})$$ 中 $$\alpha_1,\alpha_2$$ 视作变量，其余的 $$\alpha_i i=3,4,...,N$$ 的参数视为常数，则原优化目标函数变换如下：

$$
\begin{split}
\begin{align*}
    min\Psi(\alpha_1,\alpha_2)  =&amp;\frac{1}{2}K_{11}\alpha_{1}^2y_1^2 + \frac{1}{2}K_{22}\alpha_{2}^2y_2^2 \\
   &amp; + \frac12K_{12}\alpha_1\alpha_2y_1y_2 + \frac12K_{21}\alpha_2\alpha_1y_2y_1 \\
   &amp; - (\alpha_1 + \alpha_2)  + y_1v_1\alpha_1 + y_2v_2\alpha_2 + P
\end{align*}
\end{split}\tag{2-1}
$$

由于，$$y_i^2 = 1$$，$$K_{ij}= K_{ji}$$，化简可得：

$$
\begin{split}
\begin{align*}
    min\Psi(\alpha_1,\alpha_2) 
       =&amp;\frac12K_{11}\alpha_1^2 + \frac12K_{22}\alpha_2^2 + K_{12}\alpha_1\alpha_2y_1y_2\\ 
       &amp;-(\alpha_1 + \alpha_2) + y_1v_1\alpha_1 + y_2v_2\alpha_2 + P
\end{align*}
\end{split}\tag{2-2}
$$

其中，$$K_{ij}$$ 为核函数&lt;br/&gt;
　　$$v_i = \sum\limits_{j=3}^{N} \alpha_jy_jK_{ij} = 0 $$ &lt;br/&gt;
　　$$P$$ 为常数项

#### 用 $$\alpha_2$$ 表示 $$\alpha_1$$

由 $$\sum\limits_{i=1}^{N} \alpha_iy_i = 0$$ 得：

$$
    \alpha_1y_1 + \alpha_2y_2 = - \sum\limits_{i=3}^{N} \alpha_iy_i = \zeta \tag{2-3}
$$

等式两边同时乘 $$y_1$$ 可得：

$$
    \alpha_1 = (\zeta - y_2\alpha_2)y_1 \tag{2-4}
$$

将 (2-4) 代入到 (2-2) 可得：

$$
\begin{align*}
    \Psi(\alpha_2) = &amp;\frac12K_{11}(\zeta - \alpha_2y_2)^2y_1^2 + \frac12K_{22}\alpha_2^2 + K_{12}(\zeta - \alpha_2y_2)\alpha_2y_1^2y_2\\
                    &amp; -(\zeta - \alpha_2y_2)y_1 - \alpha_2 + v_1(\zeta - \alpha_2y_2)y_1^2 + y_2v_2\alpha_2 + P

\end{align*} \tag{2-5}
$$

化简可得：

$$
    \begin{align*}
        \Psi(\alpha_2) = &amp; \frac12K_{11}(\zeta - \alpha_2y_2)^2 + \frac12K_{22}\alpha_2^2 + K_{12}(\zeta - \alpha_2y_2)\alpha_2y_2\\
        &amp; -(\zeta - \alpha_2y_2)y_1 - \alpha_2 + v_1(\zeta - \alpha_2y_2) + y_2v_2\alpha_2 + P
    \end{align*} \tag{2-6}
$$

#### 对 $$\alpha_2$$ 求极值
由 (2-6) 可知，现在目标函数只是关于 $$\alpha_2$$ 的函数，对其求导并令它等于 0 

$$
\begin{align}
    \frac{\partial \Psi (\alpha_2)}{\partial \alpha_2}&amp;=(K_{11}+K_{22}-2K_{12})\alpha_2-K_{11}\zeta y_2+K_{12}\zeta y_2\\
    &amp;\quad+y_1y_2-1-v_1y_2+v_2y_2\\
    &amp; =0
\end{align} \tag{2-7}
$$

SMO 的思想是一个迭代求解的思想，所以必须构造出 $$\alpha_2^{new}$$ 与 $$\alpha_2^{old}$$ 之间的关系，由 (2-3) 可知：

$$
    \alpha_1^{new}y_1 + \alpha_2^{new}y_2 = \alpha_1^{old}y_1 + \alpha_2^{old}y_2 = \zeta \tag{2-8}
$$

由

 $$
 \begin{align*}
    &amp;f(x) =\omega^T x + b  = \sum_{i=1}^{N} \alpha_iy_iK_{ix} + b\\
    &amp;v_i = \sum\limits_{j=3}^{N}\alpha_jy_jK_{ij} \quad\quad i=1,2
 \end{align*} \tag{2-9}
 $$

 可得

 $$
 \begin{align*}
    v_1 = f(x_1) - \sum\limits_{j=1}^{2}\alpha_jy_jK_{1j} - b = f(x) - \alpha_1y_1K_{11} - \alpha_2y_2K_{12} - b \\
    v_2 = f(x_2) - \sum\limits_{j=1}^{2}\alpha_jy_jK_{2j} - b = f(x) - \alpha_1y_1K_{21} - \alpha_2y_2K_{22} - b 
\end{align*} \tag{2-10}
 $$

 将等式 (2-7) 中的 $$\zeta$$ 替换成 (2-8)，$$v_i$$ 替换成 (2-9)，$$\alpha_2$$ 表示待求值，为了和 (2-8) 中的 $$\alpha_2^{old}$$ 区分则用 $$\alpha_2^{new}$$ 表示：

$$
 \begin{align*}
    \frac{\partial \Psi (\alpha_2)}{\partial \alpha_2} = &amp;(K_{11} + K_{22} -2K_{12})\alpha_2^{new} - K_{11}(\alpha_1^{old}y_1 + \alpha_2^{old}y_2)y_2\\
    &amp;+ K_{12}(\alpha_1^{old}y_1 + \alpha_2^{old}y_2)y_2 + y_1y_2 - 1\\
    &amp;- \left[f(x_1) - \alpha_1^{old}y_1K_{11} - \alpha_2^{old}y_2K_{12} - b\right]y_2 \\
    &amp;+ \left[f(x_2) - \alpha_1^{old}y_1K_{21} - \alpha_2^{old}y_2K_{22} - b\right]y_2 \\
    &amp;= 0
 \end{align*} \tag{2-11}
 $$


对 (2-11) 进行展开

$$
\begin{align*}
    (k_{11} + K_{22} - 2K_{12})\alpha_2^{new} = &amp; K_{11}\alpha_1^{old}y_1y_2 + K_{11}\alpha_2^{old}y_2^2 - K_{12}\alpha_1^{old}y_1y_2\\
     &amp; - K_{12}\alpha_2^{old}y_2^2 - y_1y_2 + 1 + f(x_1)y_2 - K_{11}\alpha_1^{old}y_1y_2 \\
     &amp; - K_{12}\alpha_2^{old}y_2^2 - by_2 - f(x_2)y_2 + K_{12}\alpha_1^{old}y_1y_2 \\
     &amp; + K_{22}\alpha_2^{old}y_2^2 + by_2
\end{align*} \tag{2-12}
$$

由 $$y_i^2 = 1$$ 化简可得

 $$
 \begin{align*}
    (K_{11}+K_{22}-2K_{12})\alpha_2^{new}=&amp;(K_{11}+K_{22}-2K_{12})\alpha_2^{old}\\
    &amp; +y_2\left[(f(x_1) - y_1) - (f(x_2) - y_2)\right]
\end{align*}\tag{2-13}
 $$

令 $$Ei = f(x_i) - y_i$$，$$\eta = K_{11} + K_{22} - 2K_{12}$$，可得

 $$
    \alpha_2^{new}=\alpha_2^{old}+\frac{y_2(E_1-E_2)}{\eta}
    \tag{2-14}
 $$

其中，$$\alpha_2^{new}$$ 表示本次迭代的计算值，$$\alpha_2^{old}$$ 为上一次的迭代值 &lt;br/&gt;
　　$$E_i = f(x_i) - y_i$$ 表示预测值与真实值的差 &lt;br/&gt;
　　$$\eta=K_{11}+K_{22}-2K_{12} $$ 

#### $$\alpha_2^{new}$$ 的约束
　　上面通过求导的方式计算出的 $$\alpha_2^{new}$$ 是未经过约束的，即计算出来的值可能不满足约定的条件

$$
\begin{cases}
    0 \le \alpha_i \le C \\
    \alpha_1y_1 + \alpha_2y_2 = \zeta
\end{cases}\tag{2-15}
$$

这两个约束条件可以在二维平面上进行直观的展示

   [![alpha-constrains][img1]][img1]{:data-lightbox=&quot;smo&quot;}

上图横坐标为 $$\alpha_1$$，纵坐标为 $$\alpha_2$$，$$\alpha_2^{new}$$ 必须要在方框内和斜线上取值，其最大最小值一定是其交点，所以有 $$L \le \alpha_2^{new} \le H $$

1. 当 $$y_1 \ne y_2$$ 时，$$L = max\left(0,\alpha_2^{old} - \alpha_1^{old}\right)$$；$$H = min\left(C,C+\alpha_2^{old} - \alpha_1^{old}\right)$$
1. 当 $$y_1 = y_2$$ 时，$$L = max\left(0, \alpha_1^{old} + \alpha_2^{old} - C\right)$$；$$H = min\left(C,\alpha_2^{old} + \alpha_1^{old}\right)$$

所以 $$\alpha_2^{new}$$ 的约束如下：

$$
    \alpha_2^{new} = 
\begin{cases}
    H, \alpha_2^{new,unc} &gt; H\\
    \alpha_2^{new,unc}, L \le \alpha_2^{new,unc} \le H \\
    L, \alpha_2^{new,unc} &lt; L
\end{cases} \tag{2-16}
$$

其中，$$\alpha_2^{new,unc}$$ 表示 $$\alpha_2^{new}$$ 未经约束的结果（上述通过求导的结果）

#### 求解 $$\alpha_1^{new}$$

由公式 (2-8) 可知

$$
    \alpha_1^{new} = \alpha_1^{old} + y_1y_2(\alpha_2^{old} - \alpha_2^{new}) \tag{2-17}
$$ 

　　至此，通过公式 (2-14)，(2-16)，(2-17) 可以接出 $$\alpha_1^{new}$$ 和 $$\alpha_2^{new}$$，SMO 算法的核心逻辑已介绍完毕，后面将介绍如何选取变量 $$\alpha_1$$ 和 $$\alpha_2$$ 以及对 SVM 优化目标中的 $$b$$ 求值。

### SMO 变量选取

#### 第一个变量选择
　　第一个变量的选择称为外循环，首先遍历整个样本然后选择违反 KKT 条件的 $$\alpha_i$$ 作为第一个变量，其 KKT 条件如下：

$$
    \begin{aligned}
     \alpha_{i}=0 &amp; \Rightarrow y_i\left(w^{T} x_i+b\right) \geq 1 \\ 
     \alpha_{i}=C &amp; \Rightarrow y_i\left(w^{T} x_i+b\right) \leq 1 \\ 
     0&lt;\alpha_{i}&lt;C &amp; \Rightarrow y_i\left(w^{T} x_i+b\right)=1 
    \end{aligned}
$$

&gt;  一般而言，首选选择违反 $$ 0&lt;\alpha_{i}&lt;C  \Rightarrow y_i\left(w^{T} x_i+b\right)=1$$ 这个条件点

&gt;  如果支持向量都满足 KKT 条件，再选择 $$\alpha_{i}=0  \Rightarrow y_i\left(w^{T} x_i+b\right) \geq 1$$ 和 $$\alpha_{i}=C \Rightarrow y_i\left(w^{T} x_i+b\right) \leq 1 $$ 这两个条件点

#### 第二个变量选择
　　第二个变量选择的过程为内循环，选择 $$|E_1 - E_2|$$ 取得最大值的 $$\alpha_2$$
&gt; 如果内循环中找不到点能够使目标函数有足够的下降，则可遍历支持向量来做 $$\alpha_2$$

&gt; 如果所有支持向量均不能使得目标函数有足够的下降，则跳出循环，重新选择 $$\alpha_1$$

### SMO 阈值 $$b$$ 的计算

**1.　若 $$0 &lt; \alpha_1^{new} &lt; C$$，则**

由 $$y_1 = \left(\omega^Tx_1 + b\right) = \sum_{i=1}^{N} K_{i1}\alpha_iy_i + b$$ 得：

$$
    b_1^{new} = y_1 - \sum\limits_{i=3}^{N}K_{i1}\alpha_iy_i - K_{11}\alpha_1^{new}y_1  - K_{21}\alpha_2^{new}y_2\tag{4-1}
$$

而

$$
\begin{align*}
    y_1 - \sum\limits_{i=3}^{N}K_{i1}\alpha_iy_i  &amp;= y_1 - f(x_1) + K_{11}\alpha_1^{old}y_1 + K_{21}\alpha_2^{old}y_2 + b^{old} 
\end{align*}\tag{4-2}
$$

将 (4-2) 代入到 (4-1) 得：

$$
\begin{align*}
    b_1^{new} = &amp; y_1 - f(x_1) + K_{11}\alpha_1^{old}y_1 + K_{21}\alpha_2^{old}y_2 + b^{old} \\
    &amp;- \alpha_1^{new}y_1K_{11} - \alpha_2^{new}y_2K_{21}        
\end{align*}\tag{4-3}
$$

由 $$E_i = f(x_i) - y_i $$ 化简可得：

$$
\begin{align*}
   b^{new} =  b_{1}^{new}=-E_{1}-y_{1} K_{11}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{21}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}
\end{align*}\tag{4-4}
$$

**2.　若 $$0 &lt; \alpha_2^{new} &lt; C$$，则**

$$
   b^{new} =  b_{2}^{new}=-E_{2}-y_{1} K_{12}\left(\alpha_{1}^{new}-\alpha_{1}^{old}\right)-y_{2} K_{22}\left(\alpha_{2}^{new}-\alpha_{2}^{old}\right)+b^{old}\tag{4-5}
$$

**3.　若同时满足 $$0 &lt; \alpha_i^{new} &lt; C$$，则**

$$
    b^{new} = b_1^{new} = b_2^{new}\tag{4-6}
$$

**4.　若同时不满足 $$ 0 &lt; \alpha_i^{new} &lt; C $$，则**

$$
    b^{new} = \frac{b_1^{new}  + b_2^{new}}{2} \tag{4-7}
$$

关于上述取值分析可参考：[SMO算法在更新参数b过程中的疑问][href2]

至此，SMO 算法剖析完毕。

### 总结
　　输入是 N 个样本 $$(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$$，其中 $$x_i$$ 为输入特征，$$y_i$$ 为样本分类（只能取 $$1$$ 或者 $$-1$$），输出是近似解 $$\alpha$$
&gt; 注：$$\alpha_i$$ 并不是只能取 $$1$$ 或 $$-1$$

求解步骤：

1. 取初值 $$\alpha = 0,t=0$$
1. 选择变量 $$\alpha_1^t$$ 和 $$\alpha_2^t$$，根据公式求解出 $$\alpha_2^{t+1}$$
1. 利用 $$\alpha_1^{t+1}$$ 和 $$\alpha_1^t,\alpha_2^t,\alpha_2^{t+1}$$ 的关系求解出 $$\alpha_1^{t+1}$$
1. 通过 $$\alpha_1^{t+1}$$ 和 $$\alpha_2^{t+1}$$ 的满足的 KKT 条件关系求出 $$b^{t+1}$$
1. 检查 $$E_i$$ 是否在允许的精度 $$e$$ 之内
1. 检查求出的 $$\alpha_1^{t+1}$$ 和  $$\alpha_2^{t+1}$$ 是否满足 KKT 条件
1. 如果上面两个条件都满足则返回 $$\alpha_1^{t+1}$$ 和 $$\alpha_2^{t+1}$$，否则跳转到第 2 步

　　SMO 算法可以实现对 SVM 的目标函数的快速优化，其推导过程是十分复杂的，所以需要有耐心将它一一进行剖析，但是 SMO 的求解步骤是十分清晰的，下一步将通过代码实现 SMO 算法。

[href1]: /2019/04/03/ml-svm/
[href2]: https://ask.julyedu.com/question/696


[img1]: /images/post/ml/smo-alpha-constrains.jpg</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="推荐" /><category term="SMO" /><category term="SVM" /><category term="机器学习" /><summary type="html">1996年，John Platt 发布一个称为 SMO（Sequential Minimal Optimization，序列最小优化）的强大算法，用于训练 SVM，该算法的核心思想是将原问题分解成多个小问题分别进行优化求解。</summary></entry><entry><title type="html">真正理解拉格朗日乘子法和 KKT 条件</title><link href="http://0.0.0.0:4800/2019/04/06/lagrange-kkt/" rel="alternate" type="text/html" title="真正理解拉格朗日乘子法和 KKT 条件" /><published>2019-04-06T00:00:00+00:00</published><updated>2019-04-06T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/06/lagrange-kkt</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/06/lagrange-kkt/">　　这篇博文以直观的方式讲解了拉格朗日乘子法和 KKT 条件，对偶问题等内容。

### 无约束优化

　　首先从无约束的优化问题讲起，一般就是要使一个表达式取到最小值：

$$
    min\ f(x)
$$

　　如果求 $$max\ f(x)$$ 也可以通过取反转化为求 $$min\ (−f(x))$$ 的问题，然后对它的每一个变量求求，然后让偏导为零，解方程组就行了。

   [![kkt][img1]][img1]{:data-lightbox=&quot;kkt&quot;}

　　如图可知，在极值点处一定满足 $$\frac{df(x)}{dx}=0$$（只是必要条件，比如 $$f(x)=x^3$$ 在 $$x=0$$ 处就不是极值点）然后对它进行求解，再代入验证是否真的是极值点就行了，对于有些问题可以直接通过这种方法求出解析解（如最小二乘法）。

　　但是也有很多问题解不出来或者很难解，所以就需要梯度下降法、牛顿法、坐标下降法之类的数值迭代算法了（感知机 、logistic 回归中用到）。

　　对于这些迭代算法就像下面这张图一样，我们希望找到其中的最小值，一个比较直观的想法是先找一个起点，然后不断向最低点靠近，就像把一个小球放到一个碗里一样。

   [![iter][img2]][img2]{:data-lightbox=&quot;kkt&quot;}

　　一开始要找一个起始点，然后确定走的方向和距离，最后还要知道什么时候停止，这三步中最难的是确定走的方向，因为走的慢点还可以接受，要是方向错了就找不到最小值了，所以走的距离可以简单的设为一个比较小的值，起始点可以随机选一个 $$(x_0,y_0)$$，然后是确定方向，一般选择 $$(x_0,y_0)$$ 处梯度的反方向，这是函数在这个点下降最快的方向（原因可以看[知乎][href1]中忆臻的回答），它是一个向量，然后它的大小就是走的距离，为了防止太大而走过头，导致不断在最小值附近来回震荡，所以需要乘上一个比较小的因子（称为学习率），最终的停止条件就是梯度的大小很接近于 0（在极值点处的梯度大小为 0），这种方法依靠梯度确定下降方向的方法叫做梯度下降法。

　　对 $$f(x)$$ 求极小值的流程就是：

1. 随机选定 $$x_0$$
1. 得到函数在 $$x_0$$ 的梯度，然后从 $$x_0$$ 向前走一步：$$x_0^{new0}=x_0^{old0}−\alpha\nabla{f(x)}$$
1. 重复第 2 步，直到梯度接近于 0（小于一个事先设定的很小的数），或者到达指定的迭代上限，如下图所示

   [![gradient-des][img3]][img3]{:data-lightbox=&quot;kkt&quot;}

    除了这种方法之外，其中第 2 步还可以这样做，将 $$x$$ 固定为常数，这样就变成只有一个变量的优化问题了，直接求导为 0 就可以得到最优点，向前走到 $$(x_0,y_1)$$ 处，然后固定 $$y_1$$, 对 $$x$$ 进行相同的操作，这种每次只优化一个变量的方法叫做坐标下降法，如下图所示

   [![coordlinate-des][img4]][img4]{:data-lightbox=&quot;kkt&quot;}

### 等式束优化

    进一步的，我们可能要在满足一定约束条件的情况下最小化目标函数，比如有一个等式约束：

$$
\begin{cases}
    min\ f(x)\\
    s.t.\ h(x) = 0
\end{cases}
$$

   [![extremum-constraint][img5]][img5]{:data-lightbox=&quot;kkt&quot;}

    该问题不能通过求 $$f(x)$$ 的极值点来解决，因为这个问题的解可能根本不是 $$min\ f(x)$$ 的解，那么还是要从问题本身去找线索：

    如图，其中的圆圈是指目标函数 $$f(x，y)$$ 投影在平面上的等值线，表示在同一个圆圈上，黑线是约束条件 $$h(x)=0$$ 的函数图像，可知，等值线与函数图像相交的点其实就是所有满足约束的点，那么极值点只有可能在等值线与函数图像相切的地方取到，因为如果在相交的地方取到，那么沿着 $$h(x)$$ 的图像往前走或者往后走，一定还有其它的等值线与它相交，也就是 $$f(x,y)$$ 的值还能变大和变小，所以交点不是极值点，只有相切的时候才有可能是极值点。在相切的地方 $$h(x)$$ 的梯度和 $$f(x,y)$$ 的梯度应该是在同一条直线上的。（这一点可以这么想，在切点处两个函数的梯度都与切平面垂直，所以在一条直线上）

    所以满足条件的极值点一定满足：$$∇f(x,y)=λ∇h(x,y)$$ ( $$λ=0$$ 是允许的，表示 $$f(x,y)$$ 本身的极值点刚好在切点上)，然后和原来的等式方程 $$h(x,y)=0$$ 联立，然后只要解出这个方程组，就可以得到问题的解析解了。当然也存在解不出来的情况，就需要用罚函数法之类的方法求数值解。

    为了方便和好记，就把原来的优化问题写成 $$f(x,y)+λh(x,y)$$ 的形式，然后分别对 $$λ,x,y$$ 求偏导，并令之等于 0，该方法称之为拉格朗日乘数法。

    如果有多个等式约束怎么办呢，如下图：

   [![extremum-multi-constraint][img6]][img6]{:data-lightbox=&quot;kkt&quot;}

    这里的平面和球面分别代表了两个约束 $$h_1(x)$$ 和 $$h_2(x)$$，那么这个问题的可行域就是它们相交的那个圆。这里蓝色箭头表示平面的梯度，黑色箭头表示球面的梯度，那么相交的圆的梯度就是它们的线性组合（只是直观上的），所以在极值点的地方目标函数的梯度和约束的梯度的线性组合在一条直线上。所以就满足：

$$
\begin{cases}
   \nabla f(x) = \lambda \sum_{i=1}^{2}{\mu_{i}\nabla h_i(x)}=\sum_{i=1}^{2}\lambda_{i}\nabla h_i(x)\\
h_1(x)=0\\
h_2(x)=0
\end{cases}
$$

    对于大于 2 个约束的情况也一样，令 $$L(x,λ)=f(x)+\sum_{i=1}^{n}λ_i∇h_i(x)$$ 然后分别对 $$x、λ$$ 求偏导并令它们为 0，这个可以看做是一种简记，或者是对偶问题，这个函数叫做拉格朗日函数。

### 不等式约束优化
    再进一步，如果问题中既有等式约束，又有不等式约束怎么办呢？对于：

$$
   \begin{cases}
   min\ f(x)\\
   s.t.\\ 
   \quad h(x) = 0\\
   \quad g(x) \le 0
   \end{cases}
$$

   当然也同样约定不等式是 $$\le$$，如果是 $$\ge$$ 只要取反就行了。对于这个问题先不看等式约束，对于不等式约束和目标函数如下图：

   [![inequation-constraint][img7]][img7]{:data-lightbox=&quot;kkt&quot;}

    阴影部分就是可行域，也就是说可行域从原来的一条线变成了一块区域。那么能取到极值点的地方可能有两种情况：

1. 还是在 $$h(x)$$ 和 等值线相切的地方
1. $$f(x)$$ 的极值点本身就在可行域里面

    因为如果不是相切，那么同样的，对任意一个在可行域中的点，如果在它附近往里走或者往外走，$$f(x)$$ 一般都会变大或者变小，所以绝大部分点都不会是极值点，除非这个点刚好在交界处，且和等值线相切，或者这个点在可行域内部，其本身就是 $$f(x)$$ 的极值点，如下图：

   [![inequation-extremum][img8]][img8]{:data-lightbox=&quot;kkt&quot;}

    对于右边的情况，不等式约束就变成等式约束了，对 $$f(x)+λh(x)+μg(x)$$ 用拉格朗日乘子法：

$$
   \begin{cases}
      \nabla f(x)+\lambda \nabla h(x)+\mu \nabla g(x) = 0\\
      h(x)=0\\
      g(x)=0\\
      \mu \geq 0
   \end{cases}
$$

    这里需要解释一下，为什么不是 $$μ \ne 0$$ 而是 $$\mu \ge 0$$，后面的约束比前面的更强，已知问题中的可行域是在 $$g(x)≤0$$ 一侧，而由上上个图可知 $$g(x)$$ 的梯度是指向大于 0 的一侧，也就为可行域相反的一侧，而求的问题是极小值，而 $$f(x)$$ 在交点处的梯度是指向可行域的一侧，也就是说两个梯度一定是相反的，所以也就可以确定这里的系数一定是大于 0 的，而等式约束由于不知道 $$h(x)$$ 的梯度方向，所以对它没有约束， 而 $$\mu = 0 $$ 是因为极值点可能刚好在 $$g(x)$$ 上。

    对于左边的情况，不等式约束就相当于没有，对 $$f(x)+\lambda h(x)$$ 用拉格朗日乘子法：

$$
   \begin{cases}
      \nabla f(x)+\lambda \nabla h(x)= 0\\
      h(x)=0\\
      g(x) \leq 0
   \end{cases}
$$

    最好把两种情况用同一组方程表示出来。对比一下两个问题，不同的是第一种情况中有 $$\mu \ge 0$$ 且 $$g(x)=0$$, 第二种情况 $$\mu = 0$$ 且 $$g(x) \le 0$$ ，综合两种情况，可以写成 $$\mu g(x)=0$$ 且 $$\mu \ge 0，g(x) \le 0$$：

$$
   \begin{cases}
      \nabla f(x)+\lambda \nabla h(x)+\mu \nabla g(x) = 0\\
         \mu g(x) = 0\\
         \mu \geq 0 \\
         h(x)=0\\
         g(x) \leq 0
   \end{cases}
$$

### KKT 条件
    上述不等式约束优化就是 KKT 条件，它的含义是这个优化问题的极值点一定满足这组方程组（不是极值点也可能会满足，但是不会存在某个极值点不满足的情况）它也是原来的优化问题取得极值的必要条件，解出来了极值点之后还是要代入验证的。但是因为约束比较多，情况比较复杂，KKT 条件并不是对于任何情况都是满足的。要满足 KKT 条件需要有一些规范性条件（Regularity conditions），就是要求约束条件的质量不能太差，常见的比如：

1. LCQ：如果 $$h(x)$$ 和 $$g(x)$$ 都是形如 $$Ax+b$$ 的仿射函数，那么极值一定满足 KKT 条件。
1. LICQ：起作用的 $$g(x)$$ 函数（$$g(x)$$ 相当于等式约束的情况）和 $$h(x)$$ 函数在极值点处的梯度线性无关，那么极值一定满足 KKT 条件。
1. Slater：如果优化问题是个凸优化问题，且至少存在一个点满足 $$h(x)=0$$ 和 $$g(x)=0$$，极值一定满足 KKT 条件，并且满足强对偶性质。

    这里的 Slater 条件比较重要，因为它可以推导出强对偶性质（比 KKT 条件还好）。它需要原问题是凸优化问题，所谓凸优化就是这个优化问题的优化函数是凸函数，并且可行域是凸集，可行域数凸集就要求其中的 $$h(x) \le 0$$ 的条件中 $$h(x)$$ 必须也是凸函数，而 $$g(x) \le 0$$ 中的 $$g(x)$$ 必须是 $$Ax+b$$ 形式的，也就是仿射函数（比如二维的情况，可行域就在 $$g(x)$$ 这条曲线上，那么 $$g(x)$$ 必须得是直线才能满足凸集的定义）。

    其它条件还有很多，可以看[维基百科][href2]。

    如果有多组等式约束 $$h_i(x)=0(i=1,..,n)$$, 和不等式约束 $$g_i(x) \ne 0(i=1,..,n)$$ 也是一样，只要做个线性组合就行了：

$$
   \begin{cases}
      \nabla f(x)+\sum_{i=1}^{n}\lambda_i \nabla h_i(x)+\sum_{i=1}^{n}\mu_i \nabla g_i(x) = 0\\
      \mu_i g(x)_i = 0\\
      \mu_i \geq 0\\
      h_i(x)=0\\
      g_i(x) \leq 0\\
      i = 1,2,...,n
   \end{cases}
$$

    问题到这里就大致解决了，KKT 条件虽然从理论上给出了极值的必要条件，但是一般实际解的时候直接方程也是很困难的（特别是约束很多的时候），一般也会采用罚函数法等数值方法。

### 对偶问题
    为了更好的解决这个优化问题，数学家还找到了它的对偶问题，找一个优化问题的对偶问题的一般因为是对偶问题比原问题更好解决，并且对偶问题的解和原问题是一样的，上面的拉格朗日函数也可以看做原问题的对偶问题。

    为了去掉问题中的约束，可以把它们作为惩罚项加到目标函数中 $$min_xf(x)+Mh(x)+Ng(x)$$ 其中 M, N 是两个很大的正数，在数值解法中可以直接这样做，这个就是罚函数法的思路。不过在理论推导时这样做是不严谨的，除非 M, N 为无穷大，可改写 $$L(x,μ,λ)=min_{x}max_{\mu,\lambda} f(x)+\lambda h(x)+\mu g(x)$$。这个式子可以这么理解，现在外层给定任意一个 $$x_0$$ 值，然后内层在给定的 $$x_0$$ 下优化那个函数，让它最小。然后外层选能够让内层得到的值最大的一个 $$x_0$$，得到的函数表达式就是：

$$
   L(x,\mu,\lambda)=
            \left\{\begin{matrix}
            f(x) &amp; (x \quad满足约束)\\
            \infty &amp; (x \quad不满足约束)\\ 
            \end{matrix}\right.
$$

    所以外层选的那个 $$x_0$$ 一定满足约束，否则，内层的 $$max$$ 的时候会让 $$\mu$$ 或者 $$\lambda$$ 为无穷大，外层不会选那些能让内层得到无穷大的 $$x$$ 值，这样改写就和原来的带约束形式完全一致了，但是形式不同。这样可以利用 $$max[min\ f(x)] \le min[max\ f(x)]$$ 这个公式（这个很好理解，$$min\ f(x) \le min[max\ f(x)]$$, 然后就有这个公式了），得到原问题的最小值的一个下界，就是:

$$
   min_{x}max_{\mu,\lambda}f(x) + \lambda h(x) + \mu g(x)  \geq  max_{\mu,\lambda}min_{x}f(x) + \lambda h(x) + \mu g(x)
$$

    前面的就是原函数，后面的是它的一个下界。那么为什么要这样做呢? 是因为后面的一定是一个凸规划（理论上证明了的），比较好解决。但是这个只是一个下界，它们之间还是有一定的差距。这个差距叫对偶误差（duality gap）。对偶误差如果为 0 其实是一个非常好的性质，表示可以直接求解后面的问题得到原问题的解，这种性质叫强对偶性质，否则就只是弱对偶。

    强对偶性质非常好，但是要求也很苛刻，比 KKT 条件要苛刻。如果问题满足强对偶一定也满足 KKT 条件，反之不一定。对于这类优化问题，KKT 条件、强对偶、规范性条件之间的关系是：

   [![kkt-rc-relation][img9]][img9]{:data-lightbox=&quot;kkt&quot;}


[href1]: https://www.zhihu.com/question/36301367
[href2]: https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions

[img1]: /images/post/ml/extremum-value-sketch.png
[img2]: /images/post/ml/extremum-iter.jpg
[img3]: /images/post/ml/gradient-des.jpg
[img4]: /images/post/ml/coordlinate-des.jpg
[img5]: /images/post/ml/extremum-constraint.png
[img6]: /images/post/ml/extremum-multi-constraint.png
[img7]: /images/post/ml/kkt-inequation-constraint.png
[img8]: /images/post/ml/kkt-extremum-inequation.png
[img9]: /images/post/ml/kkt-rc-relation.png</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="KKT" /><category term="拉格朗日乘子法" /><summary type="html">KKT 条件是解决最优化问题的时用到的一种方法。最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值。</summary></entry><entry><title type="html">支持向量机通俗导论（理解SVM的三层境界）</title><link href="http://0.0.0.0:4800/2019/04/03/ml-svm/" rel="alternate" type="text/html" title="支持向量机通俗导论（理解SVM的三层境界）" /><published>2019-04-03T00:00:00+00:00</published><updated>2019-04-03T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/04/03/ml-svm</id><content type="html" xml:base="http://0.0.0.0:4800/2019/04/03/ml-svm/"></content><author><name>Aiesst</name></author><category term="机器学习" /><category term="推荐" /><category term="机器学习" /><category term="SVM" /><summary type="html">支持向量机，因其英文名为support vector machine，故一般简称SVM，通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</summary></entry><entry><title type="html">机器学习-决策树-ID3</title><link href="http://0.0.0.0:4800/2019/03/28/ml-decision-tree-id3/" rel="alternate" type="text/html" title="机器学习-决策树-ID3" /><published>2019-03-28T00:00:00+00:00</published><updated>2019-03-28T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2019/03/28/ml-decision-tree-id3</id><content type="html" xml:base="http://0.0.0.0:4800/2019/03/28/ml-decision-tree-id3/">　　决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy = 系统的凌乱程度，使用算法ID3, C4.5和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。

　　决策树最经典的算法包括：ID3、C4.5以及CART算法，ID3与C4.5算法相似，C4.5在特征选择时选用的信息准则是信息增益比，而ID3用的是信息增益；因为信息增益偏向于选择具有较多可能取值的特征（例如，某一特征具有5个可能取值，其信息增益会比具有2个特征取值的信息增益大）。

### 准备

#### 信息熵

　　熵表示随机变量的不确定性，熵值越大表示随机变量含有的信息越少，变量的不确定性越大。

　　熵也是一个物理量和质量、温度、速度一样都是可以测定的，物理量的测定是需要参考物的，比如当测某个物体的质量时只需要计算该物体的重量为参考物的多少倍即可，比如参考物是 1KG，该物体的重量是它的 3 倍，那么该物体的质量为 3KG。

　　熵的测定也是一样的，不过熵表示不确定性那么选择的参考物为抛 1 个硬币（熵为 1）这种只有 2 种情况的不确定性，但是测量熵不是通过乘法来做的而是通过指数测量的，比如抛 3 个硬币（熵为 3）的情况不是 6 种而是 $$2^3 = 8$$ 种，它的熵为 $$log_2{8} = 3$$，再比如某个选择题的答案为 A B C D 中的一个，那么该题的熵为 $$log_2{4} = 2$$。即熵的一般公式为：

$$
    log_2{m}
$$

&gt; 注：m 表示事件的不确定个数

　　当事件为非等概率的时候，其每个事件的不确定个数为概率的倒数

 $$
    l(x_i) = log_2{\frac{1}{p(x_i)}} = - log_2{p(x_i)}
 $$

&gt; 注：这里的 $$\frac{1}{p(x_i)}$$ 表示 $$x_i$$ 的不确定个数

所以，样本集合的熵的计算公式如下：

$$
    H = - \sum_{i=1}^{n}{p(x_i)log_2{p(x_i)}} 
$$

$$p(x_i)$$ 表示 $$x_i$$ 在总样本中的概率，熵的单位是 bit(比特)

关于熵解释还可以参考知乎 [信息熵是什么？][href1]

#### 信息增益
　　信息增益在决策树算法中是用来选择特征的指标，信息增益越大，则这个特征的选择性越好，在概率中定义为：待分类的集合的熵和选定某个特征的条件熵之差（这里只的是经验熵或经验条件熵，由于真正的熵并不知道，是根据样本计算出来的），公式如下：

$$
    IG(X|Y) = H(Y) - H(Y|X)
$$

信息增益就是 （含所有特征的熵 — 缺少某特征的熵）

#### 决策树
　　决策树的结构是一个树状的，每一节点都是一个决策点，通过做不同的决策可以将样本分到最终叶子点的不同分类里面去，比如下图所示的一个要不要去约会的决策判断

[![decision-tree][img1]][img1]{:data-lightbox=&quot;decision-tree&quot;}


#### ID3 实现

#### 计算信息熵
```python
    def calcEntropy(dataSet):
    &quot;&quot;&quot;
    :param dataSet: 样本集合，最后一列为分类数据
    :return: 分类数据的信息熵
    &quot;&quot;&quot;
    labelsCount = {}
    for line in dataSet:
        # 分类标签
        label = line[-1]
        labelsCount[label] = labelsCount.get(label, 0) + 1
    entroy = 0.0
    for key in labelsCount:
        # 计算熵
        p = float(labelsCount[key]) / len(dataSet)
        entroy -= p * math.log(p, 2)
    return entroy
```

#### 划分数据集
```python
    def splitDataSet(dataSet, index, value):
    &quot;&quot;&quot;
    删除样本的指定列
    :param dataSet: 输入样本
    :param index: 列序号
    :param value: 样本中的列特征值等于 value 才有效
    :return: 取出样本中指定列特征等于 value 的所有样本，且删除掉指定的列
    &quot;&quot;&quot;
    result = []
    for feats in dataSet:
        if feats[index] == value:
            feat = feats[:index]
            feat.extend(feats[index + 1:])
            result.append(feat)
    return result
```

#### 选择最好的划分方式
```python
    def chooseBestFeat(dataSet):
        &quot;&quot;&quot;
        选择合适的特征列作为样本的划分标准，该特征为区分样本的最好的特征
        :param dataSet: 样本集合
        :return: 特征列序号
        &quot;&quot;&quot;
        # 最后一列为分类信息，不是特征
        featuresCount = len(dataSet[0]) - 1
        # 整体的信息熵
        entropy = calcEntropy(dataSet)
        bestInfoGain = 0.0
        bestFeature = -1
        for i in range(featuresCount):
            # 样本的某一列
            featVals = [ex[i] for ex in dataSet]
            # 过滤掉重复值
            uniquVals = set(featVals)
            subEntropy = 0.0
            for value in uniquVals:
                # 切分样本
                subDataSet = splitDataSet(dataSet, i, value)
                # 计算切分后的信息熵
                p = len(subDataSet) / float(len(dataSet))
                subEntropy += p * calcEntropy(subDataSet)
            # 整体的信息熵 - 子样本的信息熵
            # 差值越大说明信息增益越大
            infoGain = entropy - subEntropy
            if infoGain &gt; bestInfoGain:
                bestInfoGain = infoGain
                bestFeature = i
        return bestFeature
```

#### 简单的决策树
```python
    def classify(inputTree, featLabels, testVec):
        &quot;&quot;&quot;
        一个简单的决策树抉择
        :param inputTree: 决策树的结构，该结构为手动实现，通过上述的划分特征来获取各个决策点
        :param featLabels: 每个特征的名字
        :param testVec: 测试样本
        :return: 测试样本所属的分类
        &quot;&quot;&quot;
        key = inputTree.keys()[0]
        root = inputTree[key]
        # 当前测试的特征
        featIndex = featLabels.index(key)
        classLabel = -1
        for k in root.keys():
            # 抉择分类
            if testVec[featIndex] == k:
                # 决策点
                if type(root).__name__ == &quot;dict&quot;:
                    classLabel = classify(root[k], featLabels, testVec)
                # 终结点
                else:
                    classLabel = root[k]
        return classLabel
```

### 总结
　　决策树分类就是一个带有终止块的流程图，终止块代表了分类结果。处理数据时根据信息增益来找到最好的划分数据的方式，直到将所有同一类数据划分到一起为止，然后可以通过递归的方式来判断出测试数据所属的分类。

[href1]: https://www.zhihu.com/question/22178202/answer/49929786

[img1]: /images/post/ml/decision-tree.png</content><author><name>Aiesst</name></author><category term="机器学习" /><category term="机器学习" /><category term="决策树" /><category term="ID3" /><summary type="html">决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。</summary></entry><entry><title type="html">准备面试</title><link href="http://0.0.0.0:4800/2018/03/10/prepare-interview/" rel="alternate" type="text/html" title="准备面试" /><published>2018-03-10T00:00:00+00:00</published><updated>2018-03-10T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/03/10/prepare-interview</id><content type="html" xml:base="http://0.0.0.0:4800/2018/03/10/prepare-interview/">1. B/B+/红黑树的定义、性质、效率等等
1. Skip List (跳跃表)的定义、性质、效率等等
1. 树的一些属性、度与顶点的关系等等
1. 十大排序算法的实现、效率对比等等
1. 字符串的二进制哈夫曼编码
1. 入栈顺序可能的出栈顺序
&gt; 1、在原序列中相对位置比它小的，必须是逆序；   
&gt; 2、在原序列中相对位置比它大的，顺序没有要求；   
&gt; 3、以上两点可以间插进行。  
1. 判断有向图回路（拓扑排序）
1. 编译过程
&gt; 预编译处理(.c) －－&gt;编译、优化程序（.s、.asm）－－&gt;汇编程序(.obj、.o、.a、.ko)－－&gt; 链接程序（.exe、.elf、.axf等）
1. 指针和引用的区别
1. 函数模板和模板函数
1. fork() 函数的返回结果
1. 死代码、函数内联、强度削弱等定义</content><author><name>Aiesst</name></author><category term="Private" /><category term="Private" /><summary type="html">总结自己为了找工作而准备的知识点，提升自己的硬实力，同时也为了找一份好的工作。</summary></entry><entry><title type="html">程序员代码面试指南 树</title><link href="http://0.0.0.0:4800/2018/03/06/it-guide-tree/" rel="alternate" type="text/html" title="程序员代码面试指南 树" /><published>2018-03-06T00:00:00+00:00</published><updated>2018-03-06T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/03/06/it-guide-tree</id><content type="html" xml:base="http://0.0.0.0:4800/2018/03/06/it-guide-tree/"></content><author><name>Aiesst</name></author><category term="刷题" /><category term="刷题" /><category term="Java" /><category term="Tree" /><summary type="html">程序员面试指南 树 相关部分的题目</summary></entry><entry><title type="html">C 语言在 x86 和 x64 平台下面各个类型的长度</title><link href="http://0.0.0.0:4800/2018/03/01/c-x86-x64-type-bytes/" rel="alternate" type="text/html" title="C 语言在 x86 和 x64 平台下面各个类型的长度" /><published>2018-03-01T00:00:00+00:00</published><updated>2018-03-01T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/03/01/c-x86-x64-type-bytes</id><content type="html" xml:base="http://0.0.0.0:4800/2018/03/01/c-x86-x64-type-bytes/">### 对比表

|类型             | x86   |x64    |                   备注             |
| --------------- | ----- | ----- | --------------------------------- |
| **char**        | 1     | 1     |                                   |
| **short**       | 2     | 2     |                                   |
| **int**         | 4     | 4     |                                   |
| **long**        | 4     | 8     | 32位与64位不同                     |
| **float**       | 4     | 4     |                                   |
| **char \***     | 4     | 8     | 其他指针类型如long *, int * 也是如此  |
| **long long**   | 8     | 8     |                                   |
| **double**      | 8     | 8     |                                   |
| **long double** | 10/12 | 10/16 | 有效位10字节。32位为了对齐实际分配12字节；64位分配16字节 

### 小结
通过上表，可以看出，对于32位和64位机器，只有long和指针类型的长度不一样，其它类型所占字节数都是一样的（long double除外，见注释）。</content><author><name>Aiesst</name></author><category term="杂记" /><category term="C" /><summary type="html">在日常开发和面试中经常会遇到关于 C 语言内存空间占用的问题，本文只是简单总结各个类型所占用的空间</summary></entry><entry><title type="html">蓝魔平板刷 Android Windows Linux</title><link href="http://0.0.0.0:4800/2018/02/27/ramos-brush/" rel="alternate" type="text/html" title="蓝魔平板刷 Android Windows Linux" /><published>2018-02-27T00:00:00+00:00</published><updated>2018-02-27T00:00:00+00:00</updated><id>http://0.0.0.0:4800/2018/02/27/ramos-brush</id><content type="html" xml:base="http://0.0.0.0:4800/2018/02/27/ramos-brush/">本文是以「蓝魔 i9s Pro」为例，其它 x86平板 也可以参考刷机的过程  
&lt;font color=&quot;red&quot;&gt;如果你是其它平板，请不要下载本文提供的系统文件，工具文件是通用的&lt;/font&gt;

### 准备
1. 一根 OTG 线
1. 一个 Hub 集线器
1. 一个 U 盘 （会将其数据抹掉）
1. 一个键盘、鼠标
1. 文件： 链接：[https://pan.baidu.com/s/1o9TV3Jk][href2] 密码：01xy  
&gt; 镜像：蓝魔官方 Andorid，Windows8.1，非官方 Windows10，Ubuntu For Tablet，Remix
&gt; 工具：Android Bios，Windows Bios，MTF 刷机工具，分区文件 partition.rar，Root 工具等

### 说明
1. Android，Windows，Linux 三个系统使用的 Bios 不一样
1. Android 的 Bios 是 x64 的
1. Windows 和 Linux 的 Bios 是 x86 的
1. 刷 Android 之前就需要刷入 Android 的 Bios，其它两系统类似
1. 目前仅支持 Android 和 Windows 共存

### 单刷 Android
1. 刷入 Android Bios
    * 将 Windows PE 烧写的 U 盘，制作成启动盘   
      烧写工具为 Rufus，PE 为 WinPE_5.1_x86_for_Tablet_1.7.iso
      &gt; 注意：烧写的时候会清空 U 盘，烧写模式为 UEFI + GPT
    * 将 Bios 文件拷进 U 盘 （i9s-bios-android/stage01) 文件夹里面的文件  
    * 将 OTG + HUB + 鼠标 + 键盘 + U 盘， 连接到平板上面，然后开机不断 按 F7 会出现启动选项，请选择 U 盘启动
    * 进入 Windows PE 后执行刚刚拷贝的 stage01/flash.bat 文件刷入 Android Bios
    * 关机
1. 刷入 Android 系统
    * 文件为 MTF.rar 和 i9spro-Android.rar
    * 安装 38186_iSoC_USB_Driver_Setup_1_2_0
    * 安装 38185_Intel_Android_Driver_Setup_1_5_0
    * 安装 ManufacturingFlashTool_Setup_6.0.43.exe
    * 把 CUSTOM_CONFIG.INI 这个文件复制到 ManufacturingFlashTool 的安装目录
    * 打开 MFT，选择 File -&gt; settings，SOC device设置为：VID:8087，PID:0A65，其它不用改动
    * 加载flash.xmli9spro-android.rar 里面）：点击 file -&gt; open，找到固件的 xml 文件打开即可
        &gt; 可根据自己的需要选择分区文件覆盖 partition.tbl，在 partition.rar 里面有 5G, 8G, 16G, 24G, 48G 的分区文件
    * i9s关机，按住 「音量+」「靠近电源键那个音量按钮」不要放开，使用usb线连接到电脑，电脑识别到设备之后就会自动升级，5分钟左右升级完成自动重启 
    * 重启，直接进入Android，点击桌面上的「迈微双启动」图标，启动该应用（解开所需文件）后，即可退出。若出现「该应用需要重启机器后才可使用」，则重启机器后再次启动该应用，然后关机；注意，之后就暂时不要再进入Android，也就是说，在你安装好 Windows 之前，只能够进入 2 次 Android 系统（如果第 3 次不小心开机进入了 Android，必须到 bios setup 里面执行 restore default，否则会没有双启动界面出来！）
1. 修改 Android 分区大小
    * 修改 i9spro-android.rar 的 partition.tbl 最后两个 add 行，例如官方的 24G 如下：
      ```
        add -b 5406760 -s 50331648 -t data -u 80868086-8086-8086-8086-000000000008 -l data -T 0 -P 0 /dev/block/mmcblk0
        add -b 55738408 -s 4096 -t data -u 80868086-8086-8086-8086-000000000009 -l guest-firmware -T 0 -P 0 /dev/block/mmcblk0
        reload /dev/block/mmcblk
      ```
      其中 50331648 = 24 * 1024 * 2048  
          55738408 = 5406760 + 50331648  
    * 可知，修改方法如下：
      ```
        add -b 5406760 -s X -t data -u 80868086-8086-8086-8086-000000000008 -l data -T 0 -P 0 /dev/block/mmcblk0
        add -b Y -s 4096 -t data -u 80868086-8086-8086-8086-000000000009 -l guest-firmware -T 0 -P 0 /dev/block/mmcblk0
        reload /dev/block/mmcblk
      ```
      其中：  
    　　  X = G * 1024 * 2048 (G &lt;= 55.5，G 为 Android 的储存空间 GB 数)  
      　　Y = 5406760 + X

### 共存刷 Windows
1. 刷入 Windows  BIOS
    * 下载好「i9s-bios-windows」之后，把 fparts.txt、fpt64.efi、startup.nsh，I9S_SPINOR_11_W.bin 共 4 个文件复制到 u盘 根目录。
    * 把u盘、键盘插入到 usb hub 并通过 OTG 线连接到 i9s Pro
    * i9s长按3秒开机，出现 logo 之后马上不停的按键盘上的 F7 功能键，待出现启动选项菜单后，选择「UEFI:Built-in EFI Shell」，回车键确认，等待 5秒 后即可自动开始更换为 「win8 BIOS」的
    * 更新完成后，i9s会自动重启进入fastboot模式
    &gt; 注意：如果你是初次刷此bios，此时屏幕是没有任何显示的  
    * 在电脑上安装「IntelAndroidDrvSetup1.5.0.exe」（已安装过的电脑不需要重复安装）
    * i9s Pro 通过 usb线 连接到电脑，在电脑上双击「1升级bios_stage2.bat」，稍等片刻即可完成升级。然后i9s会重启并有显示内容出现。此时可长按十秒钟强制关机。至此「Windows BIOS」就更换完成了  
     &gt; 注意：刷了 WIN8 的 BIOS 以后，不能进入 Android 系统  
     &gt; 万一进入了，处理方法为：重启进入到 BIOS 界面，在最后一项「Save or exit」中，选中「restore Defaults」后，直接回车，选yes,然后返回到第一项「save changes and exit」，再直接回车，选 yes,自动重启，便可接着刷 win8 系统了
1. 刷入 官方 Windows 8.1
    * 把 「i9spro-win8.1-20150106官方固件」 复制到格式化为 FAT32 的 u盘 根目录（u盘 卷标记得改为 WINPE ），通过 OTG 线连接到 i9s Pro，开机即可从 u盘 启动并自动部署好 win8 系统了（如果默认不从 u盘 启动，请接 usb hub、键盘、u盘 在开机时马上不停按 F7 键再选择从 u盘 启动），等待 20分钟 左右部署完成。如果刷的官方部署文件，当在 system32 停下来后，先拔掉U盘，再用键盘输入「EXIT」，机器会自动重启，再选「通用」后，确定。 
    * 通过双启动菜单选择进入Windows，在 C盘 的 MicroVirt 目录下找到「MicroVirtSetup.exe」文件，双击运行，执行完安装过程
    * 安装完成后，进入「C:\Program Files\MicroVirt\Dualboot」，点击「MicroVirtAt.exe」执行，今后该软件将自动加载
    * 点击任务栏右下角的迈微「M」图标
    * 点击「加载Android数据分区」 -- 此时Android分区被映射，并在桌面上已经创建快捷方式（实现 Android 空间在 Windows 系统上共享）

1. 刷入 非官方 Windows 10
    * 文件在「i9sPro-win10-非官方」，刷入方式同上
    * 需要在 Windows10 系统中隐藏 Android 的众多分区，以免不小心点中格式化，破坏 Android 系统
    * 下载 partitionhide 文件，通过u盘复制到 Windows 系统的 C盘 根目录
    * 长按桌面左下角的 Win 图标，在弹出的菜单中选择「命令提示符（管理员）（A）」打开命令窗口
    * 输入以下内容并按回车键即可(正常的话可以看到十几行提示，如某某盘符已被移除之类的)
      ```
    diskpart /s c:\partitionhide
    注意：以上命令全部为小写字母，在/s参数的前、后各有一个空格
      ```
    * 修改双系统切换后 Windows 时间比 Android 慢 8小时 的问题
    * 进入 Windows 系统，进行如下修改：
    &gt; 在左下角「开始」按钮长按，选择「运行」，输入 regedit 并回车打开注册表，打开如下项目：HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\TimeZoneInformation\
新建一个「DWORD(32位)值（D）」，名称改为「RealTimeIsUniversal」，值设为 1 的键值，重启后就可以保持系统时间和 Android 一致了

### 单刷 Linux
请参考 [在 x86 平板上面安装 Ubuntu][href1]

### 参考
[I9S和I9SPRO双系统详细完整教程以及额外说明][href3]

[href1]: /2017/04/11/install-ubuntu-on-tablet/
[href2]: https://pan.baidu.com/s/1o9TV3Jk
[href3]: http://tieba.baidu.com/p/3530141496</content><author><name>Aiesst</name></author><category term="系统" /><category term="平板" /><category term="刷机" /><summary type="html">不仅是蓝魔其它厂的 x86平板 刷机原理都是类似的，支持 Android，Windows，Linux 之间的互刷</summary></entry></feed>